{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d06e108-c781-41dd-9e3d-c6f279b628b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "E: Unable to locate package r-base\n",
      "E: Unable to locate package r-base-dev\n",
      "E: Unable to locate package cmake\n",
      "E: Unable to locate package libnlopt-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Warning messages:\n",
      "\n",
      "R[write to console]: 1: \n",
      "R[write to console]: In (function (pkgs, lib, repos = getOption(\"repos\"), contriburl = contrib.url(repos,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  installation of package ‘nloptr’ had non-zero exit status\n",
      "\n",
      "R[write to console]: 2: \n",
      "R[write to console]: In (function (pkgs, lib, repos = getOption(\"repos\"), contriburl = contrib.url(repos,  :\n",
      "R[write to console]: \n",
      " \n",
      "R[write to console]:  installation of package ‘lme4’ had non-zero exit status\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y \\\n",
    "    r-base \\\n",
    "    r-base-dev \\\n",
    "    cmake \\\n",
    "    libnlopt-dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001cc8a6-b346-40d5-adf0-62e50909193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: statsmodels in /opt/conda/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: patsy in /opt/conda/lib/python3.11/site-packages (0.5.3)\n",
      "Collecting pymer4\n",
      "  Downloading pymer4-0.8.2-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: rpy2 in /opt/conda/lib/python3.11/site-packages (3.5.11)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.24.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.11.3)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (2.1.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from patsy) (1.16.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from pymer4) (0.13.0)\n",
      "Requirement already satisfied: matplotlib>=3.0 in /opt/conda/lib/python3.11/site-packages (from pymer4) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.11/site-packages (from pymer4) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.11/site-packages (from pymer4) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from rpy2) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from rpy2) (3.1.2)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from rpy2) (2023.3.post1)\n",
      "Requirement already satisfied: tzlocal in /opt/conda/lib/python3.11/site-packages (from rpy2) (5.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.10.0->rpy2) (2.21)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.0->pymer4) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.0->pymer4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.0->pymer4) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.0->pymer4) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.0->pymer4) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.0->pymer4) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.0->pymer4) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.0->pymer4) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->rpy2) (2.1.3)\n",
      "Downloading pymer4-0.8.2-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.9/136.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymer4\n",
      "Successfully installed pymer4-0.8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels patsy pymer4 rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb379a6-fc17-4b48-9df1-c86eb1b42557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Using R 4.3.1 (lockfile was generated with R 4.4.1)\n",
      "- Project '/local' loaded. [renv 1.0.7]\n",
      "- One or more packages recorded in the lockfile are not installed.\n",
      "- Use `renv::status()` for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Installing packages into ‘/local/renv/library/R-4.3/x86_64-conda-linux-gnu’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/nloptr_2.1.1.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 2236635 bytes (2.1 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 2.1 MB\n",
      "\n",
      "\n",
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/lme4_1.1-35.5.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 3300116 bytes (3.1 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 3.1 MB\n",
      "\n",
      "\n",
      "* installing *source* package ‘nloptr’ ...\n",
      "** package ‘nloptr’ successfully unpacked and MD5 sums checked\n",
      "** using staged installation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking whether the C++ compiler works... yes\n",
      "checking for C++ compiler default output file name... a.out\n",
      "checking for suffix of executables... \n",
      "checking whether we are cross compiling... no\n",
      "checking for suffix of object files... o\n",
      "checking whether the compiler supports GNU C++... yes\n",
      "checking whether x86_64-conda-linux-gnu-c++ -std=gnu++17 accepts -g... yes\n",
      "checking for x86_64-conda-linux-gnu-c++ -std=gnu++17 option to enable C++11 features... none needed\n",
      "checking how to run the C++ preprocessor... x86_64-conda-linux-gnu-c++ -std=gnu++17 -E\n",
      "checking whether the compiler supports GNU C++... (cached) yes\n",
      "checking whether x86_64-conda-linux-gnu-c++ -std=gnu++17 accepts -g... (cached) yes\n",
      "checking for x86_64-conda-linux-gnu-c++ -std=gnu++17 option to enable C++11 features... (cached) none needed\n",
      "checking for pkg-config... no\n",
      "checking for cmake... no\n",
      "\n",
      "------------------ CMAKE NOT FOUND --------------------\n",
      "\n",
      "CMake was not found on the PATH. Please install CMake:\n",
      "\n",
      " - sudo yum install cmake          (Fedora/CentOS; inside a terminal)\n",
      " - sudo apt install cmake          (Debian/Ubuntu; inside a terminal).\n",
      " - sudo pacman -S cmake            (Arch Linux; inside a terminal).\n",
      " - brew install --cask cmake       (MacOS; inside a terminal with Homebrew)\n",
      " - sudo port install cmake         (MacOS; inside a terminal with MacPorts)\n",
      "\n",
      "Alternatively install CMake from: <https://cmake.org/>\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: configuration failed for package ‘nloptr’\n",
      "* removing ‘/local/renv/library/R-4.3/x86_64-conda-linux-gnu/nloptr’\n",
      "ERROR: dependency ‘nloptr’ is not available for package ‘lme4’\n",
      "* removing ‘/local/renv/library/R-4.3/x86_64-conda-linux-gnu/lme4’\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/Rtmpw1Vw8n/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import rpy2\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "\n",
    "# Install the utils package to manage installation\n",
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)  # Select the first mirror in the list\n",
    "\n",
    "# Define the packages to be installed\n",
    "packnames = ('nloptr', 'lme4')\n",
    "\n",
    "# Check which packages are not installed\n",
    "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
    "\n",
    "# Install the missing packages\n",
    "if len(names_to_install) > 0:\n",
    "    utils.install_packages(StrVector(names_to_install))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ac3ea-430b-4a4e-83e0-428ba0faec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\n",
    "from tqdm import tqdm\n",
    "from patsy import dmatrices\n",
    "from patsy import dmatrix\n",
    "from statsmodels.discrete.count_model import ZeroInflatedPoisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251927b-09b7-49ef-b966-05d4988eb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = pd.read_csv('./2024_Jul_ob_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996374c-c0b0-4973-9d12-40f7c7b80f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of category names as they appear in the detections data. See paper for details of each category.\n",
    "categories = ['car', 'person', 'trotro', 'stall', 'truck', 'stove', 'motorcycle', 'vendor', 'lorry', 'umbrella', 'bus', 'trash', 'taxi', 'van', 'debris', 'loudspeaker', 'bowl', 'food', 'animal', 'bicycle']\n",
    "\n",
    "# Column names in the data frame for the number of counts of each category type in an image.\n",
    "count_cols = [cat+'_counts' for cat in categories]\n",
    "\n",
    "super_count_cols = ['people'+'_counts', 'small_vehicles'+'_counts', 'two_wheelers'+'_counts', 'large_vehicles'+'_counts', 'refuse'+'_counts', 'market'+'_counts', 'animal'+'_counts']\n",
    "\n",
    "all_count_cols = count_cols + super_count_cols\n",
    "\n",
    "vehicle_categories = ['car', 'trotro', 'truck', 'motorcycle', 'lorry', 'bus', 'taxi', 'van', 'bicycle']\n",
    "\n",
    "# Define super categories\n",
    "super_categories = {\n",
    "    'people': ['person', 'vendor'],\n",
    "    'small_vehicles': ['car', 'taxi', 'truck'],\n",
    "    'two_wheelers': ['bicycle', 'motorcycle'],\n",
    "    'large_vehicles': ['trotro', 'van', 'lorry', 'bus'],\n",
    "    'refuse': ['trash', 'debris'],\n",
    "    'market': ['umbrella', 'stall', 'bowl', 'food'],\n",
    "    'animal': ['animal']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6bd7b-c000-4515-bd02-e192ea9eca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime is in datetime format\n",
    "object_data['datetime'] = pd.to_datetime(object_data['datetime_rectified'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Create additional time-related columns\n",
    "object_data['hour'] = object_data['datetime'].dt.hour\n",
    "object_data['day'] = object_data['datetime'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "object_data['week'] = object_data['datetime'].dt.isocalendar().week\n",
    "object_data['year'] = object_data['datetime'].dt.year\n",
    "\n",
    "# Split 'site_id_cam_angle' into 'site_id' and 'camera' columns\n",
    "object_data[['site_id', 'camera']] = object_data['site_id_cam_angle'].str.split('_', expand=True)\n",
    "\n",
    "# Fill missing values in 'camera' with 'single'\n",
    "object_data['camera'].fillna('single', inplace=True)\n",
    "\n",
    "# Filter data between specified dates\n",
    "start_date = pd.Timestamp('2019-04-01')\n",
    "end_date = pd.Timestamp('2024-04-01')\n",
    "fixed_object_data = object_data[(object_data['datetime'] >= start_date) & (object_data['datetime'] <= end_date)]\n",
    "fixed_object_data = fixed_object_data[fixed_object_data['view'] == 'clear']\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "fixed_object_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa3c9c-1c82-44cd-bd98-03d4de85848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum counts for each super category\n",
    "for super_cat, categories in super_categories.items():\n",
    "    # Create a column for each supercategory by summing its categories\n",
    "    fixed_object_data[super_cat + '_counts'] = fixed_object_data[[cat + '_counts' for cat in categories]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c13aec-e259-46dd-b08b-bd60886ed36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Round the 'datetime' to the nearest hour\n",
    "fixed_object_data['datetime_hour'] = fixed_object_data['datetime'].dt.round('H')\n",
    "\n",
    "# Step 8: Sum the counts within each hour for each camera at each site\n",
    "hourly_counts = fixed_object_data.groupby(['site_id', 'camera', 'datetime_hour'])[all_count_cols].sum().reset_index()\n",
    "\n",
    "# Step 9: Group by the rounded 'datetime', 'date', and 'site_id', then calculate the mean for each object category\n",
    "hourly_averages = hourly_counts.groupby(['site_id', 'datetime_hour'])[all_count_cols].mean().reset_index()\n",
    "\n",
    "# Step 10: Add the date column from the rounded 'datetime_hour'\n",
    "hourly_averages['date'] = hourly_averages['datetime_hour'].dt.date\n",
    "\n",
    "# Create additional time-related columns\n",
    "hourly_averages['hour'] = hourly_averages['datetime_hour'].dt.hour\n",
    "hourly_averages['day'] = hourly_averages['datetime_hour'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "hourly_averages['week'] = hourly_averages['datetime_hour'].dt.isocalendar().week\n",
    "hourly_averages['year'] = hourly_averages['datetime_hour'].dt.year\n",
    "\n",
    "\n",
    "# Step 11: Reorder the columns to match the requested format\n",
    "final_columns = ['datetime_hour', 'date', 'site_id', 'hour', 'day', 'week', 'year'] + all_count_cols\n",
    "hourly_averages = hourly_averages[final_columns]\n",
    "\n",
    "# Step 12: Rename 'datetime_hour' to 'datetime' to match the final requested column name\n",
    "hourly_averages.rename(columns={'datetime_hour': 'datetime'}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "hourly_averages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568817f-a3d4-4bfb-9d83-860a58691c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "# Step 1: Adjust the 'year' column to start from 0\n",
    "hourly_averages['year'] = hourly_averages['year'] - hourly_averages['year'].min()\n",
    "\n",
    "# Step 2: Filter the data to include only those rows with counts > 0\n",
    "filtered_data = hourly_averages[hourly_averages['people_counts'] > 0]\n",
    "\n",
    "# Step 3: One-hot encode 'hour', 'day', 'week', and 'site_id' for fixed effects\n",
    "exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id']], drop_first=True)\n",
    "\n",
    "# Step 4: Ensure that 'year' remains as integer and add it to exog_fixed\n",
    "exog_fixed['year'] = filtered_data['year']\n",
    "\n",
    "# Step 5: Standardize only the 'year' column\n",
    "# scaler = StandardScaler()\n",
    "# exog_fixed[['year']] = scaler.fit_transform(exog_fixed[['year']])\n",
    "\n",
    "# Step 6: Prepare the dataset for pymer4\n",
    "data_for_pymer = pd.concat([filtered_data[['people_counts', 'hour', 'day', 'week', 'site_id']], exog_fixed], axis=1)\n",
    "\n",
    "# Step 7: Create the formula for the mixed model\n",
    "fixed_effects_formula = ' + '.join(exog_fixed.columns)\n",
    "formula = f'people_counts ~ {fixed_effects_formula} + (1|hour) + (1|day) + (1|week) + (1|site_id)'\n",
    "\n",
    "# Step 8: Fit the Poisson mixed model\n",
    "model = Lmer(formula, data=data_for_pymer, family='poisson')\n",
    "result = model.fit()\n",
    "\n",
    "# Step 9: Display the results\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42feaefa-58b8-4edd-83c0-d16f7e1bb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Adjust the 'year' column to start from 0\n",
    "hourly_averages['year'] = hourly_averages['year'] - hourly_averages['year'].min()\n",
    "\n",
    "# Step 2: Filter the data to include only those rows with counts > 0\n",
    "filtered_data = hourly_averages[hourly_averages['people_counts'] > 0]\n",
    "\n",
    "# Step 3: Create the endogenous variable (response variable)\n",
    "endog = filtered_data['people_counts'].astype(int)\n",
    "\n",
    "# Step 4: One-hot encode 'hour', 'day', 'week', and 'site_id' for fixed effects\n",
    "exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id']], drop_first=True)\n",
    "\n",
    "# Step 5: Ensure that 'year' remains as integer and add it to exog_fixed\n",
    "exog_fixed['year'] = filtered_data['year']\n",
    "\n",
    "# Step 6: Standardize only the 'year' column\n",
    "scaler = StandardScaler()\n",
    "exog_fixed[['year']] = scaler.fit_transform(exog_fixed[['year']])\n",
    "\n",
    "# Step 7: One-hot encode 'hour', 'day', 'week', and 'site_id' for random effects\n",
    "exog_re = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id']], drop_first=True)\n",
    "\n",
    "# Step 8: Convert all boolean columns to integers to ensure no object types remain\n",
    "exog_fixed = exog_fixed.applymap(lambda x: int(x) if isinstance(x, bool) else x)\n",
    "exog_re = exog_re.applymap(lambda x: int(x) if isinstance(x, bool) else x)\n",
    "\n",
    "# Debugging: Check the data types and head of exog_fixed and exog_re\n",
    "print(\"Data types of exog_fixed after conversion:\")\n",
    "print(exog_fixed.dtypes)\n",
    "print(\"\\nexog_fixed after conversion:\")\n",
    "print(exog_fixed.head())\n",
    "\n",
    "print(\"\\nData types of exog_re after conversion:\")\n",
    "print(exog_re.dtypes)\n",
    "print(\"\\nexog_re after conversion:\")\n",
    "print(exog_re.head())\n",
    "\n",
    "# Step 9: Specify the ident vector, indicating which columns in exog_re identify the random effects\n",
    "ident = np.zeros(exog_re.shape[1], dtype=int)\n",
    "\n",
    "# Step 10: Fit the Poisson mixed-effects model\n",
    "model = PoissonBayesMixedGLM(endog, exog_fixed, exog_re, ident=ident, vcp_p=1.0)\n",
    "result = model.fit_vb()\n",
    "\n",
    "# Step 11: Display the results\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8fa0b7-78de-46a0-b393-ff519fe71852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrix\n",
    "import numpy as np\n",
    "# Define the counts column (e.g., 'car_counts') to model\n",
    "counts_column = 'person_counts'\n",
    "\n",
    "# Ensure all necessary data types are compatible and treat them as categorical\n",
    "model_fixed_object_data = hourly_averages[hourly_averages[counts_column] > 0].copy()\n",
    "model_fixed_object_data['hour'] = model_fixed_object_data['hour'].astype('category')\n",
    "model_fixed_object_data['day'] = model_fixed_object_data['day'].astype('category')\n",
    "model_fixed_object_data['week'] = model_fixed_object_data['week'].astype('category')\n",
    "model_fixed_object_data['year'] = model_fixed_object_data['year'].astype('category')\n",
    "model_fixed_object_data['site_id'] = model_fixed_object_data['site_id'].astype('category')\n",
    "\n",
    "# Fit the fixed effects model using GLM with the negative binomial family\n",
    "glm_formula = f'{counts_column} ~ C(year)'\n",
    "glm_model = smf.glm(formula=glm_formula, data=model_fixed_object_data, family=sm.families.NegativeBinomial())\n",
    "glm_results = glm_model.fit()\n",
    "\n",
    "# Print the summary of the fixed effects model\n",
    "print(glm_results.summary())\n",
    "\n",
    "# Add the predicted fixed effects to the dataset\n",
    "model_fixed_object_data['fixed_effects'] = glm_results.fittedvalues\n",
    "\n",
    "# Construct the formula for the mixed effects model\n",
    "mixed_effects_formula = 'fixed_effects ~ 1'\n",
    "\n",
    "# Fit the mixed effects model using MixedLM\n",
    "mixed_model = smf.mixedlm(mixed_effects_formula, model_fixed_object_data, groups=model_fixed_object_data['site_id'], re_formula=\"~C(hour)+C(day)+C(week)\")\n",
    "mixed_results = mixed_model.fit()\n",
    "\n",
    "# Print the summary of the mixed effects model\n",
    "print(mixed_results.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
