{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001cc8a6-b346-40d5-adf0-62e50909193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: statsmodels in /opt/conda/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: patsy in /opt/conda/lib/python3.11/site-packages (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.24.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.11.3)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (2.1.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from patsy) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095ac3ea-430b-4a4e-83e0-428ba0faec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\n",
    "from tqdm import tqdm\n",
    "from patsy import dmatrices\n",
    "from patsy import dmatrix\n",
    "from statsmodels.discrete.count_model import ZeroInflatedPoisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0251927b-09b7-49ef-b966-05d4988eb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = pd.read_csv('./2024_Jul_ob_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6996374c-c0b0-4973-9d12-40f7c7b80f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of category names as they appear in the detections data. See paper for details of each category.\n",
    "categories = ['car', 'person', 'trotro', 'stall', 'truck', 'stove', 'motorcycle', 'vendor', 'lorry', 'umbrella', 'bus', 'trash', 'taxi', 'van', 'debris', 'loudspeaker', 'bowl', 'food', 'animal', 'bicycle']\n",
    "\n",
    "# Column names in the data frame for the number of counts of each category type in an image.\n",
    "count_cols = [cat+'_counts' for cat in categories]\n",
    "\n",
    "super_count_cols = ['people'+'_counts', 'small_vehicles'+'_counts', 'two_wheelers'+'_counts', 'large_vehicles'+'_counts', 'refuse'+'_counts', 'market'+'_counts', 'animal'+'_counts']\n",
    "\n",
    "all_count_cols = count_cols + super_count_cols\n",
    "\n",
    "vehicle_categories = ['car', 'trotro', 'truck', 'motorcycle', 'lorry', 'bus', 'taxi', 'van', 'bicycle']\n",
    "\n",
    "# Define super categories\n",
    "super_categories = {\n",
    "    'people': ['person', 'vendor'],\n",
    "    'small_vehicles': ['car', 'taxi', 'truck'],\n",
    "    'two_wheelers': ['bicycle', 'motorcycle'],\n",
    "    'large_vehicles': ['trotro', 'van', 'lorry', 'bus'],\n",
    "    'refuse': ['trash', 'debris'],\n",
    "    'market': ['umbrella', 'stall', 'bowl', 'food'],\n",
    "    'animal': ['animal']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc6bd7b-c000-4515-bd02-e192ea9eca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory_name_rectified</th>\n",
       "      <th>site_id_cam_angle</th>\n",
       "      <th>view</th>\n",
       "      <th>image_name</th>\n",
       "      <th>datetime_rectified</th>\n",
       "      <th>date_rectified</th>\n",
       "      <th>animal_counts</th>\n",
       "      <th>bicycle_counts</th>\n",
       "      <th>bowl_counts</th>\n",
       "      <th>bus_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>vendor_counts</th>\n",
       "      <th>directory_name_original</th>\n",
       "      <th>datetime_original</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>site_id</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3070.JPG</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3071.JPG</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3072.JPG</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3073.JPG</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3074.JPG</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  directory_name_rectified site_id_cam_angle   view    image_name  \\\n",
       "0    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3070.JPG   \n",
       "1    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3071.JPG   \n",
       "2    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3072.JPG   \n",
       "3    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3073.JPG   \n",
       "4    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3074.JPG   \n",
       "\n",
       "    datetime_rectified date_rectified  animal_counts  bicycle_counts  \\\n",
       "0  2024-03-01 08:32:02     2024-03-01              0               0   \n",
       "1  2024-03-01 08:37:02     2024-03-01              0               1   \n",
       "2  2024-03-01 08:42:02     2024-03-01              0               0   \n",
       "3  2024-03-01 08:47:02     2024-03-01              0               0   \n",
       "4  2024-03-01 08:52:02     2024-03-01              0               0   \n",
       "\n",
       "   bowl_counts  bus_counts  ...  vendor_counts  directory_name_original  \\\n",
       "0            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "1            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "2            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "3            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "4            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "\n",
       "     datetime_original            datetime  hour  day  week  year  site_id  \\\n",
       "0  2024-03-01 08:32:02 2024-03-01 08:32:02     8    5     9  2024       AD   \n",
       "1  2024-03-01 08:37:02 2024-03-01 08:37:02     8    5     9  2024       AD   \n",
       "2  2024-03-01 08:42:02 2024-03-01 08:42:02     8    5     9  2024       AD   \n",
       "3  2024-03-01 08:47:02 2024-03-01 08:47:02     8    5     9  2024       AD   \n",
       "4  2024-03-01 08:52:02 2024-03-01 08:52:02     8    5     9  2024       AD   \n",
       "\n",
       "   camera  \n",
       "0   right  \n",
       "1   right  \n",
       "2   right  \n",
       "3   right  \n",
       "4   right  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure datetime is in datetime format\n",
    "object_data['datetime'] = pd.to_datetime(object_data['datetime_rectified'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Create additional time-related columns\n",
    "object_data['hour'] = object_data['datetime'].dt.hour\n",
    "object_data['day'] = object_data['datetime'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "object_data['week'] = object_data['datetime'].dt.isocalendar().week\n",
    "object_data['year'] = object_data['datetime'].dt.year\n",
    "\n",
    "# Split 'site_id_cam_angle' into 'site_id' and 'camera' columns\n",
    "object_data[['site_id', 'camera']] = object_data['site_id_cam_angle'].str.split('_', expand=True)\n",
    "\n",
    "# Fill missing values in 'camera' with 'single'\n",
    "object_data['camera'].fillna('single', inplace=True)\n",
    "\n",
    "# Filter data between specified dates\n",
    "start_date = pd.Timestamp('2019-04-01')\n",
    "end_date = pd.Timestamp('2024-04-01')\n",
    "fixed_object_data = object_data[(object_data['datetime'] >= start_date) & (object_data['datetime'] <= end_date)]\n",
    "fixed_object_data = fixed_object_data[fixed_object_data['view'] == 'clear']\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "fixed_object_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03aa3c9c-1c82-44cd-bd98-03d4de85848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum counts for each super category\n",
    "for super_cat, categories in super_categories.items():\n",
    "    # Create a column for each supercategory by summing its categories\n",
    "    fixed_object_data[super_cat + '_counts'] = fixed_object_data[[cat + '_counts' for cat in categories]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce8d8de0-2281-4169-9b79-c0bf05a83410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_object_data:\n",
      "  directory_name_rectified site_id_cam_angle   view    image_name  \\\n",
      "0    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3070.JPG   \n",
      "1    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3071.JPG   \n",
      "2    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3072.JPG   \n",
      "3    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3073.JPG   \n",
      "4    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3074.JPG   \n",
      "\n",
      "    datetime_rectified date_rectified  animal_counts  bicycle_counts  \\\n",
      "0  2024-03-01 08:32:02     2024-03-01              0               0   \n",
      "1  2024-03-01 08:37:02     2024-03-01              0               1   \n",
      "2  2024-03-01 08:42:02     2024-03-01              0               0   \n",
      "3  2024-03-01 08:47:02     2024-03-01              0               0   \n",
      "4  2024-03-01 08:52:02     2024-03-01              0               0   \n",
      "\n",
      "   bowl_counts  bus_counts  ...  year  site_id  camera  people_counts  \\\n",
      "0            0           0  ...  2024       AD   right              7   \n",
      "1            0           0  ...  2024       AD   right              7   \n",
      "2            0           0  ...  2024       AD   right              7   \n",
      "3            0           0  ...  2024       AD   right              8   \n",
      "4            0           0  ...  2024       AD   right              5   \n",
      "\n",
      "   small_vehicles_counts  two_wheelers_counts  large_vehicles_counts  \\\n",
      "0                      1                    0                      0   \n",
      "1                      1                    1                      1   \n",
      "2                      1                    1                      1   \n",
      "3                      5                    1                      3   \n",
      "4                      3                    0                      0   \n",
      "\n",
      "   refuse_counts  market_counts       datetime_hour  \n",
      "0              1              0 2024-03-01 09:00:00  \n",
      "1              1              0 2024-03-01 09:00:00  \n",
      "2              2              0 2024-03-01 09:00:00  \n",
      "3              1              0 2024-03-01 09:00:00  \n",
      "4              0              0 2024-03-01 09:00:00  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "hourly_counts:\n",
      "  site_id camera       datetime_hour directory_name_rectified  car_counts  \\\n",
      "0      AD   left 2019-04-12 11:00:00        AD_12_04_2019_C17         334   \n",
      "1      AD   left 2019-04-12 12:00:00        AD_12_04_2019_C17         458   \n",
      "2      AD   left 2019-04-12 13:00:00        AD_12_04_2019_C17         557   \n",
      "3      AD   left 2019-04-12 14:00:00        AD_12_04_2019_C17         502   \n",
      "4      AD   left 2019-04-12 15:00:00        AD_12_04_2019_C17         504   \n",
      "\n",
      "   person_counts  trotro_counts  stall_counts  truck_counts  stove_counts  \\\n",
      "0            148             36             0            20             0   \n",
      "1            218             65             0            36             0   \n",
      "2            179             54             0            35             0   \n",
      "3            182             86             0            12             0   \n",
      "4            230             54             0            17             0   \n",
      "\n",
      "   ...  food_counts  animal_counts  bicycle_counts  people_counts  \\\n",
      "0  ...            0              0               0            149   \n",
      "1  ...            0              0               2            219   \n",
      "2  ...            0              0               0            180   \n",
      "3  ...            0              0               1            182   \n",
      "4  ...            0              0               1            231   \n",
      "\n",
      "   small_vehicles_counts  two_wheelers_counts  large_vehicles_counts  \\\n",
      "0                    403                   11                     41   \n",
      "1                    549                   11                     76   \n",
      "2                    674                   12                     69   \n",
      "3                    578                   18                     92   \n",
      "4                    581                   27                     62   \n",
      "\n",
      "   refuse_counts  market_counts  animal_counts  \n",
      "0              0             28              0  \n",
      "1              1             35              0  \n",
      "2              3             33              0  \n",
      "3              0             22              0  \n",
      "4              0             32              0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Aggregation dictionary:\n",
      "{'car_counts': 'mean', 'person_counts': 'mean', 'trotro_counts': 'mean', 'stall_counts': 'mean', 'truck_counts': 'mean', 'stove_counts': 'mean', 'motorcycle_counts': 'mean', 'vendor_counts': 'mean', 'lorry_counts': 'mean', 'umbrella_counts': 'mean', 'bus_counts': 'mean', 'trash_counts': 'mean', 'taxi_counts': 'mean', 'van_counts': 'mean', 'debris_counts': 'mean', 'loudspeaker_counts': 'mean', 'bowl_counts': 'mean', 'food_counts': 'mean', 'animal_counts': 'mean', 'bicycle_counts': 'mean', 'people_counts': 'mean', 'small_vehicles_counts': 'mean', 'two_wheelers_counts': 'mean', 'large_vehicles_counts': 'mean', 'refuse_counts': 'mean', 'market_counts': 'mean', 'directory_name_rectified': <function aggregate_directories at 0x7fe2119a98a0>, 'camera': <function aggregate_cameras at 0x7fe2119a99e0>}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4809/2154303735.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Perform the aggregation step by step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhourly_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'datetime_hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Aggregate numeric columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mhourly_averages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_count_cols\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Aggregate directory_name_rectified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mhourly_averages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'directory_name_rectified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'directory_name_rectified'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregate_directories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0;31m# GH #52849\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_index\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \"\"\"\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_or_apply_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         with com.temp_setattr(\n\u001b[1;32m   1386\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         ):\n\u001b[0;32m-> 1388\u001b[0;31m             result_index, result_data = self.compute_dict_like(\n\u001b[0m\u001b[1;32m   1389\u001b[0m                 \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m             )\n\u001b[1;32m   1391\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_results_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mkeys\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkey_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             results = [\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    479\u001b[0m     def compute_dict_like(\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0mop_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mselected_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mselection\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;31m# Not all agg functions support numba, only propagate numba kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;31m# if user asks for numba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;31m# Catch instances of lists / tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m                 \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             )\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m             result = self._cython_agg_general(\n\u001b[0m\u001b[1;32m   2376\u001b[0m                 \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m                 \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                 \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_py_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m         \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1928\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_aggregated_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, mgr)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_agged_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mManager\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Ensure 'datetime_hour' is created properly\n",
    "# fixed_object_data['datetime_hour'] = fixed_object_data['datetime'].dt.round('H')\n",
    "# assert 'datetime_hour' in fixed_object_data.columns, \"'datetime_hour' column is missing\"\n",
    "\n",
    "# # Print the first few rows of fixed_object_data to verify 'datetime_hour'\n",
    "# print(\"fixed_object_data:\")\n",
    "# print(fixed_object_data.head())\n",
    "\n",
    "# # Sum the counts within each hour for each camera at each site and include directory_name_rectified and camera info\n",
    "# hourly_counts = fixed_object_data.groupby(['site_id', 'camera', 'datetime_hour', 'directory_name_rectified'])[all_count_cols].sum().reset_index()\n",
    "# assert 'datetime_hour' in hourly_counts.columns, \"'datetime_hour' column is missing after groupby\"\n",
    "\n",
    "# # Print the first few rows of hourly_counts to verify the groupby operation\n",
    "# print(\"\\nhourly_counts:\")\n",
    "# print(hourly_counts.head())\n",
    "\n",
    "# # Define the aggregation functions for each column\n",
    "# def aggregate_directories(x):\n",
    "#     print(\"Aggregating directories:\", x)\n",
    "#     return '|'.join(sorted(set(x)))\n",
    "\n",
    "# def aggregate_cameras(x):\n",
    "#     print(\"Aggregating cameras:\", x)\n",
    "#     return ','.join(sorted(set(x)))\n",
    "\n",
    "# # Group by the rounded 'datetime', 'site_id', then calculate the mean for each object category\n",
    "# agg_dict = {col: 'mean' for col in all_count_cols}\n",
    "# agg_dict['directory_name_rectified'] = aggregate_directories\n",
    "# agg_dict['camera'] = aggregate_cameras\n",
    "\n",
    "# print(\"Aggregation dictionary:\")\n",
    "# print(agg_dict)\n",
    "\n",
    "# # Perform the aggregation step by step\n",
    "# grouped = hourly_counts.groupby(['site_id', 'datetime_hour'])\n",
    "\n",
    "# # Aggregate numeric columns\n",
    "# hourly_averages = grouped.agg({col: 'mean' for col in all_count_cols}).reset_index()\n",
    "\n",
    "# # Aggregate directory_name_rectified\n",
    "# hourly_averages['directory_name_rectified'] = grouped['directory_name_rectified'].apply(aggregate_directories).values\n",
    "\n",
    "# # Aggregate camera\n",
    "# hourly_averages['camera'] = grouped['camera'].apply(aggregate_cameras).values\n",
    "\n",
    "# assert 'datetime_hour' in hourly_averages.columns, \"'datetime_hour' column is missing after aggregation\"\n",
    "\n",
    "# # Print the first few rows of hourly_averages to verify the aggregation\n",
    "# print(\"\\nhourly_averages:\")\n",
    "# print(hourly_averages.head())\n",
    "\n",
    "# # Add the date column from the rounded 'datetime_hour'\n",
    "# hourly_averages['date'] = hourly_averages['datetime_hour'].dt.date\n",
    "\n",
    "# # Create additional time-related columns\n",
    "# hourly_averages['hour'] = hourly_averages['datetime_hour'].dt.hour\n",
    "# hourly_averages['day'] = hourly_averages['datetime_hour'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "# hourly_averages['week'] = hourly_averages['datetime_hour'].dt.isocalendar().week\n",
    "# hourly_averages['year'] = hourly_averages['datetime_hour'].dt.year\n",
    "\n",
    "# # Add the left and right camera indicator columns\n",
    "# hourly_averages['left_cam'] = hourly_averages['camera'].apply(lambda x: 1 if 'left' in x else 0)\n",
    "# hourly_averages['right_cam'] = hourly_averages['camera'].apply(lambda x: 1 if 'right' in x else 0)\n",
    "\n",
    "# # Reorder the columns to match the requested format\n",
    "# final_columns = ['datetime_hour', 'date', 'site_id', 'hour', 'day', 'week', 'year', 'directory_name_rectified', 'left_cam', 'right_cam'] + all_count_cols\n",
    "# hourly_averages = hourly_averages[final_columns]\n",
    "\n",
    "# # Rename 'datetime_hour' to 'datetime' to match the final requested column name\n",
    "# hourly_averages.rename(columns={'datetime_hour': 'datetime', 'directory_name_rectified': 'directory_pair'}, inplace=True)\n",
    "\n",
    "# # Display the first few rows of the new dataframe to verify\n",
    "# print(\"\\nfinal hourly_averages:\")\n",
    "# print(hourly_averages.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c13aec-e259-46dd-b08b-bd60886ed36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>site_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>car_counts</th>\n",
       "      <th>person_counts</th>\n",
       "      <th>trotro_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>people_counts</th>\n",
       "      <th>small_vehicles_counts</th>\n",
       "      <th>two_wheelers_counts</th>\n",
       "      <th>large_vehicles_counts</th>\n",
       "      <th>refuse_counts</th>\n",
       "      <th>market_counts</th>\n",
       "      <th>animal_counts</th>\n",
       "      <th>animal_counts</th>\n",
       "      <th>animal_counts</th>\n",
       "      <th>animal_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-12 10:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-12 11:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>228.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>...</td>\n",
       "      <td>219.5</td>\n",
       "      <td>290.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-12 12:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>314.0</td>\n",
       "      <td>230.5</td>\n",
       "      <td>49.5</td>\n",
       "      <td>...</td>\n",
       "      <td>232.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-12 13:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>371.5</td>\n",
       "      <td>192.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-12 14:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>351.5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>...</td>\n",
       "      <td>206.5</td>\n",
       "      <td>432.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime        date site_id  hour  day  week  year  car_counts  \\\n",
       "0 2019-04-12 10:00:00  2019-04-12      AD    10    5    15  2019         9.0   \n",
       "1 2019-04-12 11:00:00  2019-04-12      AD    11    5    15  2019       228.0   \n",
       "2 2019-04-12 12:00:00  2019-04-12      AD    12    5    15  2019       314.0   \n",
       "3 2019-04-12 13:00:00  2019-04-12      AD    13    5    15  2019       371.5   \n",
       "4 2019-04-12 14:00:00  2019-04-12      AD    14    5    15  2019       351.5   \n",
       "\n",
       "   person_counts  trotro_counts  ...  people_counts  small_vehicles_counts  \\\n",
       "0           32.0            3.0  ...           32.0                   15.0   \n",
       "1          219.0           30.5  ...          219.5                  290.0   \n",
       "2          230.5           49.5  ...          232.0                  400.0   \n",
       "3          192.5           43.5  ...          195.0                  482.0   \n",
       "4          205.0           60.5  ...          206.5                  432.0   \n",
       "\n",
       "   two_wheelers_counts  large_vehicles_counts  refuse_counts  market_counts  \\\n",
       "0                  3.0                    4.0            0.0            0.0   \n",
       "1                 16.5                   36.0            0.0           23.0   \n",
       "2                 17.5                   58.0            1.0           26.5   \n",
       "3                 13.0                   58.5            2.0           24.5   \n",
       "4                 21.0                   67.0            0.0           20.0   \n",
       "\n",
       "   animal_counts  animal_counts  animal_counts  animal_counts  \n",
       "0            0.0            0.0            0.0            0.0  \n",
       "1            0.0            0.0            0.0            0.0  \n",
       "2            0.0            0.0            0.0            0.0  \n",
       "3            0.0            0.0            0.0            0.0  \n",
       "4            0.0            0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Round the 'datetime' to the nearest hour\n",
    "fixed_object_data['datetime_hour'] = fixed_object_data['datetime'].dt.round('H')\n",
    "\n",
    "# Step 8: Sum the counts within each hour for each camera at each site\n",
    "hourly_counts = fixed_object_data.groupby(['site_id', 'camera', 'datetime_hour'])[all_count_cols].sum().reset_index()\n",
    "\n",
    "# Step 9: Group by the rounded 'datetime', 'date', and 'site_id', then calculate the mean for each object category\n",
    "hourly_averages = hourly_counts.groupby(['site_id', 'datetime_hour'])[all_count_cols].mean().reset_index()\n",
    "\n",
    "# Step 10: Add the date column from the rounded 'datetime_hour'\n",
    "hourly_averages['date'] = hourly_averages['datetime_hour'].dt.date\n",
    "\n",
    "# Create additional time-related columns\n",
    "hourly_averages['hour'] = hourly_averages['datetime_hour'].dt.hour\n",
    "hourly_averages['day'] = hourly_averages['datetime_hour'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "hourly_averages['week'] = hourly_averages['datetime_hour'].dt.isocalendar().week\n",
    "hourly_averages['year'] = hourly_averages['datetime_hour'].dt.year\n",
    "\n",
    "\n",
    "# Step 11: Reorder the columns to match the requested format\n",
    "final_columns = ['datetime_hour', 'date', 'site_id', 'hour', 'day', 'week', 'year'] + all_count_cols\n",
    "hourly_averages = hourly_averages[final_columns]\n",
    "\n",
    "# Step 12: Rename 'datetime_hour' to 'datetime' to match the final requested column name\n",
    "hourly_averages.rename(columns={'datetime_hour': 'datetime'}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "hourly_averages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecd6ed03-1af3-4168-877e-95172e35f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                             | 445/353738 [09:23<124:11:21,  1.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from tqdm import tqdm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import pandas as pd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# import numpy as np\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Create indicator variables for left and right cameras\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m hourly_averages[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_cam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mhourly_averages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfixed_object_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_object_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msite_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msite_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_object_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime_hour\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcamera\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m hourly_averages[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_cam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m hourly_averages\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fixed_object_data[(fixed_object_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     34\u001b[0m                                                   (fixed_object_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_hour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     35\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tqdm/std.py:920\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:10037\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10025\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10027\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10028\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10029\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10035\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10036\u001b[0m )\n\u001b[0;32m> 10037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    983\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tqdm/std.py:915\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from tqdm import tqdm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# import pandas as pd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# import numpy as np\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Create indicator variables for left and right cameras\u001b[39;00m\n\u001b[1;32m     26\u001b[0m hourly_averages[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_cam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m hourly_averages\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fixed_object_data[(\u001b[43mfixed_object_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msite_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msite_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     28\u001b[0m                                                  (fixed_object_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_hour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     29\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m hourly_averages[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_cam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m hourly_averages\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fixed_object_data[(fixed_object_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     34\u001b[0m                                                   (fixed_object_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_hour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m])][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     35\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/series.py:5799\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5796\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   5797\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 5799\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:346\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 346\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:131\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a function to determine the directory pair or single directory for each row\n",
    "def get_directory_name(row):\n",
    "    # Filter rows for the same site and datetime\n",
    "    matching_rows = fixed_object_data[(fixed_object_data['site_id'] == row['site_id']) & \n",
    "                                      (fixed_object_data['datetime_hour'] == row['datetime'])]\n",
    "    # Get unique directories and cameras\n",
    "    unique_dirs = matching_rows['directory_name_rectified'].unique()\n",
    "    unique_cameras = matching_rows['camera'].unique()\n",
    "    \n",
    "    if len(unique_dirs) == 1:\n",
    "        return unique_dirs[0]  # Single camera or only one camera available\n",
    "    else:\n",
    "        return '|'.join(sorted(unique_dirs))  # Join directories with '|' to indicate pairs\n",
    "\n",
    "# Initialize the tqdm progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply the function to create the new column with progress monitoring\n",
    "hourly_averages['directory_pair'] = hourly_averages.progress_apply(get_directory_name, axis=1)\n",
    "\n",
    "# Create indicator variables for left and right cameras\n",
    "hourly_averages['left_cam'] = hourly_averages.progress_apply(\n",
    "    lambda row: 1 if 'left' in fixed_object_data[(fixed_object_data['site_id'] == row['site_id']) & \n",
    "                                                 (fixed_object_data['datetime_hour'] == row['datetime'])]['camera'].unique() else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "hourly_averages['right_cam'] = hourly_averages.progress_apply(\n",
    "    lambda row: 1 if 'right' in fixed_object_data[(fixed_object_data['site_id'] == row['site_id']) & \n",
    "                                                  (fixed_object_data['datetime_hour'] == row['datetime'])]['camera'].unique() else 0,\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1561fa96-75a2-4469-a91f-226f12c7a45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'date', 'site_id', 'hour', 'day', 'week', 'year',\n",
       "       'car_counts', 'person_counts', 'trotro_counts', 'stall_counts',\n",
       "       'truck_counts', 'stove_counts', 'motorcycle_counts', 'vendor_counts',\n",
       "       'lorry_counts', 'umbrella_counts', 'bus_counts', 'trash_counts',\n",
       "       'taxi_counts', 'van_counts', 'debris_counts', 'loudspeaker_counts',\n",
       "       'bowl_counts', 'food_counts', 'animal_counts', 'animal_counts',\n",
       "       'animal_counts', 'animal_counts', 'bicycle_counts', 'people_counts',\n",
       "       'small_vehicles_counts', 'two_wheelers_counts', 'large_vehicles_counts',\n",
       "       'refuse_counts', 'market_counts', 'animal_counts', 'animal_counts',\n",
       "       'animal_counts', 'animal_counts', 'directory_pair'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the new dataframe to verify\n",
    "hourly_averages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367022a6-bd29-4da4-93d8-c253d7b58d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_averages.to_csv('hourly_averages_indicator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4adc2-5b77-44c0-8bdd-82df77b2a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Decide whether to include \"week\" as a variable or not\n",
    "week_bool = True\n",
    "\n",
    "# OPTIONAL Step 1: Filter the data to include only those rows with counts > 0\n",
    "filtered_data = hourly_averages.copy()\n",
    "# filtered_data = hourly_averages[hourly_averages['people_counts'] > 0].copy()\n",
    "\n",
    "# Step 2: Create the endogenous variable (response variable)\n",
    "endog = filtered_data['people_counts'].astype(int)\n",
    "\n",
    "# Step 3: Convert relevant columns to categorical\n",
    "filtered_data['hour'] = filtered_data['hour'].astype('category')\n",
    "filtered_data['day'] = filtered_data['day'].astype('category')\n",
    "if week_bool == True:\n",
    "    filtered_data['week'] = filtered_data['week'].astype('category')\n",
    "filtered_data['site_id'] = filtered_data['site_id'].astype('category')\n",
    "filtered_data['year'] = filtered_data['year'].astype('category')\n",
    "\n",
    "# Step 4: One-hot encode 'hour', 'day', 'week', 'site_id', and 'year' for fixed effects\n",
    "if week_bool == True:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id', 'year']], drop_first=True)\n",
    "else:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'site_id', 'year']], drop_first=True)\n",
    "\n",
    "# Step 5: Add intercept\n",
    "exog_fixed = sm.add_constant(exog_fixed)\n",
    "\n",
    "# Step 6: Convert exog_fixed to float\n",
    "exog_fixed = exog_fixed.astype(float)\n",
    "\n",
    "# Step 7: Fit the GLM with a Negative Binomial family\n",
    "glm_model = sm.GLM(endog, exog_fixed, family=sm.families.NegativeBinomial())\n",
    "# glm_model = sm.GLM(endog, exog_fixed, family=sm.families.Poisson())\n",
    "glm_result = glm_model.fit()\n",
    "\n",
    "# Step 8: Display the results of the fixed effects\n",
    "print(glm_result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08657dbf-96bc-4a34-ad95-e0fdef5d4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate the confidence intervals and exponentiate the coefficients\n",
    "def calculate_effects_and_ci(glm_result, var):\n",
    "    coef = glm_result.params[var]\n",
    "    conf = glm_result.conf_int().loc[var]\n",
    "    lower, upper = conf\n",
    "    return np.exp(coef), np.exp(lower), np.exp(upper)\n",
    "\n",
    "# Function to plot effects for a given variable\n",
    "def plot_effects(glm_result, var, x_labels, title, ref_class_label):\n",
    "    effects = [calculate_effects_and_ci(glm_result, v) for v in var]\n",
    "    estimates, lower_bounds, upper_bounds = zip(*effects)\n",
    "    \n",
    "    # Add the reference class at the start\n",
    "    estimates = [1] + list(estimates)\n",
    "    lower_bounds = [1] + list(lower_bounds)\n",
    "    upper_bounds = [1] + list(upper_bounds)\n",
    "    x_labels = [ref_class_label] + x_labels\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.errorbar(range(len(x_labels)), estimates, yerr=[np.array(estimates) - np.array(lower_bounds), np.array(upper_bounds) - np.array(estimates)], fmt='o', ecolor='gray', capsize=5)\n",
    "    plt.xticks(ticks=range(len(x_labels)), labels=x_labels, rotation=45)\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Multiplicative Effect on Counts')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Highlight the reference class differently\n",
    "    plt.scatter(0, 1, color='red', zorder=5, label='Reference Class')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Variables to plot\n",
    "hour_vars = [col for col in exog_fixed.columns if 'hour' in col and col != 'const']\n",
    "day_vars = [col for col in exog_fixed.columns if 'day' in col and col != 'const']\n",
    "site_vars = [col for col in exog_fixed.columns if 'site_id' in col and col != 'const']\n",
    "year_vars = [col for col in exog_fixed.columns if 'year' in col and col != 'const']\n",
    "week_vars = [col for col in exog_fixed.columns if 'week' in col and col != 'const'] if week_bool else []\n",
    "\n",
    "# X-axis labels\n",
    "hour_labels = [f'Hour {i}' for i in range(1, 24)]\n",
    "day_labels = ['Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']  # Assuming 'Mon' is the reference category\n",
    "site_labels = [label.split('_')[2] for label in site_vars]\n",
    "year_labels = [label.split('_')[1] for label in year_vars]\n",
    "week_labels = [label.split('_')[1] for label in week_vars]\n",
    "\n",
    "# Ensure the number of labels matches the number of data points\n",
    "assert len(hour_labels) == len(hour_vars)\n",
    "assert len(day_labels) == len(day_vars)\n",
    "assert len(site_labels) == len(site_vars)\n",
    "assert len(year_labels) == len(year_vars)\n",
    "if week_bool:\n",
    "    assert len(week_labels) == len(week_vars)\n",
    "\n",
    "# Plot effects\n",
    "plot_effects(glm_result, hour_vars, hour_labels, 'Effect of Hour of Day on People Counts', 'Hour 0')\n",
    "plot_effects(glm_result, day_vars, day_labels, 'Effect of Day of Week on People Counts', 'Mon')\n",
    "plot_effects(glm_result, site_vars, site_labels, 'Effect of Site ID on People Counts', 'AD')\n",
    "plot_effects(glm_result, year_vars, year_labels, 'Effect of Year on People Counts', '2019')\n",
    "\n",
    "if week_bool:\n",
    "    plot_effects(glm_result, week_vars, week_labels, 'Effect of Week on People Counts', 'Week 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff25623-0d21-4385-bce6-2ea2a9cedb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Decide whether to include \"week\" as a variable or not\n",
    "week_bool = False\n",
    "\n",
    "# OPTIONAL Step 1: Filter the data to include only those rows with counts > 0\n",
    "filtered_data = hourly_averages.copy()\n",
    "# filtered_data = hourly_averages[hourly_averages['people_counts'] > 0].copy()\n",
    "\n",
    "# Step 2: Create the endogenous variable (response variable)\n",
    "endog = filtered_data['people_counts'].astype(int)\n",
    "\n",
    "# Step 3: Convert relevant columns to categorical\n",
    "filtered_data['hour'] = filtered_data['hour'].astype('category')\n",
    "filtered_data['day'] = filtered_data['day'].astype('category')\n",
    "if week_bool == True:\n",
    "    filtered_data['week'] = filtered_data['week'].astype('category')\n",
    "filtered_data['site_id'] = filtered_data['site_id'].astype('category')\n",
    "filtered_data['year'] = filtered_data['year'].astype('category')\n",
    "\n",
    "# Step 4: One-hot encode 'hour', 'day', 'week', 'site_id', and 'year' for fixed effects\n",
    "if week_bool == True:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id', 'year']], drop_first=True)\n",
    "else:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'site_id', 'year']], drop_first=True)\n",
    "\n",
    "# Add back the reference classes manually\n",
    "exog_fixed['hour_0'] = (filtered_data['hour'] == '0').astype(float)\n",
    "exog_fixed['day_1'] = (filtered_data['day'] == '1').astype(float)\n",
    "exog_fixed['site_id_AD'] = (filtered_data['site_id'] == 'AD').astype(float)\n",
    "\n",
    "# Step 5: Add interaction terms efficiently\n",
    "interaction_terms_list = []\n",
    "for col1 in ['hour_0'] + [f'hour_{i}' for i in range(1, 24)]:\n",
    "    for col2 in ['day_1'] + [f'day_{i}' for i in range(2, 8)]:\n",
    "        interaction_terms_list.append(exog_fixed[col1] * exog_fixed[col2])\n",
    "        interaction_terms_list[-1].name = f'{col1}:{col2}'\n",
    "    for col2 in ['site_id_AD'] + [f'site_id_{id}' for id in ['ASH', 'EL', 'JT', 'LA', 'N1W', 'NM', 'TF', 'TMW', 'UGH']]:\n",
    "        interaction_terms_list.append(exog_fixed[col1] * exog_fixed[col2])\n",
    "        interaction_terms_list[-1].name = f'{col1}:{col2}'\n",
    "for col1 in ['day_1'] + [f'day_{i}' for i in range(2, 8)]:\n",
    "    for col2 in ['site_id_AD'] + [f'site_id_{id}' for id in ['ASH', 'EL', 'JT', 'LA', 'N1W', 'NM', 'TF', 'TMW', 'UGH']]:\n",
    "        interaction_terms_list.append(exog_fixed[col1] * exog_fixed[col2])\n",
    "        interaction_terms_list[-1].name = f'{col1}:{col2}'\n",
    "\n",
    "interaction_terms = pd.concat(interaction_terms_list, axis=1)\n",
    "\n",
    "# Combine the original exog_fixed with interaction terms\n",
    "exog_fixed = pd.concat([exog_fixed, interaction_terms], axis=1)\n",
    "\n",
    "# Step 6: Add intercept\n",
    "exog_fixed = sm.add_constant(exog_fixed)\n",
    "\n",
    "# Step 7: Convert exog_fixed to float\n",
    "exog_fixed = exog_fixed.astype(float)\n",
    "\n",
    "# Step 8: Fit the GLM with a Negative Binomial family\n",
    "glm_model = sm.GLM(endog, exog_fixed, family=sm.families.NegativeBinomial())\n",
    "# glm_model = sm.GLM(endog, exog_fixed, family=sm.families.Poisson())\n",
    "glm_result = glm_model.fit()\n",
    "\n",
    "# Step 9: Display the results of the fixed effects\n",
    "print(glm_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dfa8f-b0a6-45ed-874e-e122cfc7cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Prepare data for random effects model\n",
    "# Note: MixedLM in statsmodels is primarily for linear mixed models and does not support Negative Binomial directly\n",
    "\n",
    "# Fit the mixed effects model with random effects\n",
    "if week_bool == True:\n",
    "    random_effects = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id']], drop_first=True)\n",
    "else:\n",
    "    random_effects = pd.get_dummies(filtered_data[['hour', 'day', 'site_id']], drop_first=True)\n",
    "\n",
    "random_effects = sm.add_constant(random_effects).astype(float)\n",
    "\n",
    "mixed_model = sm.MixedLM(endog, exog_fixed, groups=filtered_data['site_id'])\n",
    "mixed_result = mixed_model.fit()\n",
    "\n",
    "# Step 10: Display the results of the mixed effects model\n",
    "print(mixed_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7708c9-de40-4c21-bbc1-ed54e8753bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
