{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cc8a6-b346-40d5-adf0-62e50909193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095ac3ea-430b-4a4e-83e0-428ba0faec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\n",
    "from tqdm import tqdm\n",
    "from patsy import dmatrices\n",
    "from patsy import dmatrix\n",
    "from statsmodels.discrete.count_model import ZeroInflatedPoisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0251927b-09b7-49ef-b966-05d4988eb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = pd.read_csv('./2024_Jul_ob_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6996374c-c0b0-4973-9d12-40f7c7b80f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of category names as they appear in the detections data. See paper for details of each category.\n",
    "categories = ['car', 'person', 'trotro', 'stall', 'truck', 'stove', 'motorcycle', 'vendor', 'lorry', 'umbrella', 'bus', 'trash', 'taxi', 'van', 'debris', 'loudspeaker', 'bowl', 'food', 'animal', 'bicycle']\n",
    "\n",
    "# Column names in the data frame for the number of counts of each category type in an image.\n",
    "count_cols = [cat+'_counts' for cat in categories]\n",
    "\n",
    "super_count_cols = ['people'+'_counts', 'small_vehicles'+'_counts', 'two_wheelers'+'_counts', 'large_vehicles'+'_counts', 'refuse'+'_counts', 'market'+'_counts', 'animal'+'_counts']\n",
    "\n",
    "all_count_cols = count_cols + super_count_cols\n",
    "\n",
    "vehicle_categories = ['car', 'trotro', 'truck', 'motorcycle', 'lorry', 'bus', 'taxi', 'van', 'bicycle']\n",
    "\n",
    "# Define super categories\n",
    "super_categories = {\n",
    "    'people': ['person', 'vendor'],\n",
    "    'small_vehicles': ['car', 'taxi', 'truck'],\n",
    "    'two_wheelers': ['bicycle', 'motorcycle'],\n",
    "    'large_vehicles': ['trotro', 'van', 'lorry', 'bus'],\n",
    "    'refuse': ['trash', 'debris'],\n",
    "    'market': ['umbrella', 'stall', 'bowl', 'food'],\n",
    "    'animal': ['animal']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc6bd7b-c000-4515-bd02-e192ea9eca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory_name_rectified</th>\n",
       "      <th>site_id_cam_angle</th>\n",
       "      <th>view</th>\n",
       "      <th>image_name</th>\n",
       "      <th>datetime_rectified</th>\n",
       "      <th>date_rectified</th>\n",
       "      <th>animal_counts</th>\n",
       "      <th>bicycle_counts</th>\n",
       "      <th>bowl_counts</th>\n",
       "      <th>bus_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>vendor_counts</th>\n",
       "      <th>directory_name_original</th>\n",
       "      <th>datetime_original</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>site_id</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3070.JPG</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3071.JPG</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3072.JPG</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3073.JPG</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3074.JPG</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  directory_name_rectified site_id_cam_angle   view    image_name  \\\n",
       "0    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3070.JPG   \n",
       "1    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3071.JPG   \n",
       "2    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3072.JPG   \n",
       "3    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3073.JPG   \n",
       "4    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3074.JPG   \n",
       "\n",
       "    datetime_rectified date_rectified  animal_counts  bicycle_counts  \\\n",
       "0  2024-03-01 08:32:02     2024-03-01              0               0   \n",
       "1  2024-03-01 08:37:02     2024-03-01              0               1   \n",
       "2  2024-03-01 08:42:02     2024-03-01              0               0   \n",
       "3  2024-03-01 08:47:02     2024-03-01              0               0   \n",
       "4  2024-03-01 08:52:02     2024-03-01              0               0   \n",
       "\n",
       "   bowl_counts  bus_counts  ...  vendor_counts  directory_name_original  \\\n",
       "0            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "1            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "2            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "3            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "4            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "\n",
       "     datetime_original            datetime  hour  day  week  year  site_id  \\\n",
       "0  2024-03-01 08:32:02 2024-03-01 08:32:02     8    5     9  2024       AD   \n",
       "1  2024-03-01 08:37:02 2024-03-01 08:37:02     8    5     9  2024       AD   \n",
       "2  2024-03-01 08:42:02 2024-03-01 08:42:02     8    5     9  2024       AD   \n",
       "3  2024-03-01 08:47:02 2024-03-01 08:47:02     8    5     9  2024       AD   \n",
       "4  2024-03-01 08:52:02 2024-03-01 08:52:02     8    5     9  2024       AD   \n",
       "\n",
       "   camera  \n",
       "0   right  \n",
       "1   right  \n",
       "2   right  \n",
       "3   right  \n",
       "4   right  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure datetime is in datetime format\n",
    "object_data['datetime'] = pd.to_datetime(object_data['datetime_rectified'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Create additional time-related columns\n",
    "object_data['hour'] = object_data['datetime'].dt.hour\n",
    "object_data['day'] = object_data['datetime'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "object_data['week'] = object_data['datetime'].dt.isocalendar().week\n",
    "object_data['year'] = object_data['datetime'].dt.year\n",
    "\n",
    "# Split 'site_id_cam_angle' into 'site_id' and 'camera' columns\n",
    "object_data[['site_id', 'camera']] = object_data['site_id_cam_angle'].str.split('_', expand=True)\n",
    "\n",
    "# Fill missing values in 'camera' with 'single'\n",
    "object_data['camera'].fillna('single', inplace=True)\n",
    "\n",
    "# Filter data between specified dates\n",
    "start_date = pd.Timestamp('2019-04-01')\n",
    "end_date = pd.Timestamp('2024-04-01')\n",
    "fixed_object_data = object_data[(object_data['datetime'] >= start_date) & (object_data['datetime'] <= end_date)]\n",
    "fixed_object_data = fixed_object_data[fixed_object_data['view'] == 'clear']\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "fixed_object_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03aa3c9c-1c82-44cd-bd98-03d4de85848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum counts for each super category\n",
    "for super_cat, categories in super_categories.items():\n",
    "    # Create a column for each supercategory by summing its categories\n",
    "    fixed_object_data[super_cat + '_counts'] = fixed_object_data[[cat + '_counts' for cat in categories]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c13aec-e259-46dd-b08b-bd60886ed36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>date</th>\n",
       "      <th>site_id</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>car_counts</th>\n",
       "      <th>person_counts</th>\n",
       "      <th>trotro_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>bus_counts</th>\n",
       "      <th>trash_counts</th>\n",
       "      <th>taxi_counts</th>\n",
       "      <th>van_counts</th>\n",
       "      <th>debris_counts</th>\n",
       "      <th>loudspeaker_counts</th>\n",
       "      <th>bowl_counts</th>\n",
       "      <th>food_counts</th>\n",
       "      <th>animal_counts</th>\n",
       "      <th>bicycle_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-12 10:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-12 11:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>228.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-12 12:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>314.0</td>\n",
       "      <td>230.5</td>\n",
       "      <td>49.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>59.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-12 13:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>371.5</td>\n",
       "      <td>192.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-12 14:00:00</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>AD</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>351.5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime        date site_id  hour  day  week  year  car_counts  \\\n",
       "0 2019-04-12 10:00:00  2019-04-12      AD    10    5    15  2019         9.0   \n",
       "1 2019-04-12 11:00:00  2019-04-12      AD    11    5    15  2019       228.0   \n",
       "2 2019-04-12 12:00:00  2019-04-12      AD    12    5    15  2019       314.0   \n",
       "3 2019-04-12 13:00:00  2019-04-12      AD    13    5    15  2019       371.5   \n",
       "4 2019-04-12 14:00:00  2019-04-12      AD    14    5    15  2019       351.5   \n",
       "\n",
       "   person_counts  trotro_counts  ...  bus_counts  trash_counts  taxi_counts  \\\n",
       "0           32.0            3.0  ...         0.0           0.0          6.0   \n",
       "1          219.0           30.5  ...         0.5           0.0         45.5   \n",
       "2          230.5           49.5  ...         2.0           0.5         59.5   \n",
       "3          192.5           43.5  ...         2.0           1.5         81.0   \n",
       "4          205.0           60.5  ...         1.0           0.0         62.0   \n",
       "\n",
       "   van_counts  debris_counts  loudspeaker_counts  bowl_counts  food_counts  \\\n",
       "0         1.0            0.0                 0.0          0.0          0.0   \n",
       "1         4.0            0.0                 0.0          0.5          0.0   \n",
       "2         4.0            0.5                 0.0          0.5          0.0   \n",
       "3         8.5            0.5                 0.0          1.0          0.0   \n",
       "4         3.5            0.0                 0.0          0.5          0.0   \n",
       "\n",
       "   animal_counts  bicycle_counts  \n",
       "0            0.0             0.0  \n",
       "1            0.0             0.5  \n",
       "2            0.0             2.5  \n",
       "3            0.0             0.5  \n",
       "4            0.0             1.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: Round the 'datetime' to the nearest hour\n",
    "fixed_object_data['datetime_hour'] = fixed_object_data['datetime'].dt.round('H')\n",
    "\n",
    "# Step 8: Sum the counts within each hour for each camera at each site\n",
    "hourly_counts = fixed_object_data.groupby(['site_id', 'camera', 'datetime_hour'])[count_cols].sum().reset_index()\n",
    "\n",
    "# Step 9: Group by the rounded 'datetime', 'date', and 'site_id', then calculate the mean for each object category\n",
    "hourly_averages = hourly_counts.groupby(['site_id', 'datetime_hour'])[count_cols].mean().reset_index()\n",
    "\n",
    "# Step 10: Add the date column from the rounded 'datetime_hour'\n",
    "hourly_averages['date'] = hourly_averages['datetime_hour'].dt.date\n",
    "\n",
    "# Create additional time-related columns\n",
    "hourly_averages['hour'] = hourly_averages['datetime_hour'].dt.hour\n",
    "hourly_averages['day'] = hourly_averages['datetime_hour'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "hourly_averages['week'] = hourly_averages['datetime_hour'].dt.isocalendar().week\n",
    "hourly_averages['year'] = hourly_averages['datetime_hour'].dt.year\n",
    "\n",
    "\n",
    "# Step 11: Reorder the columns to match the requested format\n",
    "final_columns = ['datetime_hour', 'date', 'site_id', 'hour', 'day', 'week', 'year'] + count_cols\n",
    "hourly_averages = hourly_averages[final_columns]\n",
    "\n",
    "# Step 12: Rename 'datetime_hour' to 'datetime' to match the final requested column name\n",
    "hourly_averages.rename(columns={'datetime_hour': 'datetime'}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "hourly_averages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d182d39-b438-477c-8a54-545bbd5973cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the counts column (e.g., 'car_counts') to model\n",
    "counts_column = 'people_counts'\n",
    "\n",
    "# Ensure the count data is greater than zero before log transformation\n",
    "model_fixed_object_data = fixed_object_data[fixed_object_data[counts_column] > 0].copy()\n",
    "\n",
    "# Ensure all necessary data types are compatible\n",
    "model_fixed_object_data['hour'] = model_fixed_object_data['hour'].astype(int)\n",
    "model_fixed_object_data['day'] = model_fixed_object_data['day'].astype(int)\n",
    "model_fixed_object_data['week'] = model_fixed_object_data['week'].astype(int)\n",
    "model_fixed_object_data['year'] = model_fixed_object_data['year'].astype(int)\n",
    "model_fixed_object_data['site_id'] = model_fixed_object_data['site_id'].astype(str)\n",
    "\n",
    "# Construct the formula for the mixed effects model\n",
    "fixed_effect_formula = '0 + year'\n",
    "random_effects = {\n",
    "    \"hour\": '0 + C(hour)',\n",
    "    \"day\": '0 + C(day)',\n",
    "    \"week\": '0 + C(week)',\n",
    "    \"site_id\": '0 + C(site_id)'\n",
    "}\n",
    "\n",
    "# Prepare the fixed effects data\n",
    "X = dmatrix(fixed_effect_formula, data=model_fixed_object_data, return_type='dataframe')\n",
    "\n",
    "# Prepare the random effects data\n",
    "exog_vc_parts = [dmatrix(val, data=model_fixed_object_data, return_type='dataframe') for val in random_effects.values()]\n",
    "exog_vc = np.hstack(exog_vc_parts)\n",
    "\n",
    "# Construct ident array matching the number of columns in exog_vc\n",
    "ident = np.concatenate([np.repeat(i, exog_vc_parts[i].shape[1]) for i in range(len(exog_vc_parts))])\n",
    "\n",
    "# Verify ident and exog_vc lengths\n",
    "print(\"Length of ident:\", len(ident))\n",
    "print(\"Number of columns in exog_vc:\", exog_vc.shape[1])\n",
    "\n",
    "# Fit the Poisson GLMM with Bayesian estimation using PoissonBayesMixedGLM\n",
    "model = PoissonBayesMixedGLM(endog=model_fixed_object_data[counts_column].values, exog=X.values, exog_vc=exog_vc, ident=ident)\n",
    "result = model.fit_vb()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8fa0b7-78de-46a0-b393-ff519fe71852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:          person_counts   No. Observations:              3816556\n",
      "Model:                            GLM   Df Residuals:                  3816550\n",
      "Model Family:        NegativeBinomial   Df Model:                            5\n",
      "Link Function:                    Log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -1.3069e+07\n",
      "Date:                Fri, 26 Jul 2024   Deviance:                   4.6104e+06\n",
      "Time:                        15:39:08   Pearson chi2:                 5.41e+06\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):           0.007899\n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           2.5483      0.001   2010.309      0.000       2.546       2.551\n",
      "C(year)[T.2020]    -0.1799      0.002   -103.938      0.000      -0.183      -0.177\n",
      "C(year)[T.2021]    -0.2418      0.002   -143.022      0.000      -0.245      -0.239\n",
      "C(year)[T.2022]    -0.1435      0.002    -82.279      0.000      -0.147      -0.140\n",
      "C(year)[T.2023]    -0.2317      0.002   -127.745      0.000      -0.235      -0.228\n",
      "C(year)[T.2024]    -0.4602      0.004   -107.267      0.000      -0.469      -0.452\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrix\n",
    "import numpy as np\n",
    "# Define the counts column (e.g., 'car_counts') to model\n",
    "counts_column = 'person_counts'\n",
    "\n",
    "# Ensure all necessary data types are compatible and treat them as categorical\n",
    "model_fixed_object_data = hourly_averages[hourly_averages[counts_column] > 0].copy()\n",
    "model_fixed_object_data['hour'] = model_fixed_object_data['hour'].astype('category')\n",
    "model_fixed_object_data['day'] = model_fixed_object_data['day'].astype('category')\n",
    "model_fixed_object_data['week'] = model_fixed_object_data['week'].astype('category')\n",
    "model_fixed_object_data['year'] = model_fixed_object_data['year'].astype('category')\n",
    "model_fixed_object_data['site_id'] = model_fixed_object_data['site_id'].astype('category')\n",
    "\n",
    "# Fit the fixed effects model using GLM with the negative binomial family\n",
    "glm_formula = f'{counts_column} ~ C(year)'\n",
    "glm_model = smf.glm(formula=glm_formula, data=model_fixed_object_data, family=sm.families.NegativeBinomial())\n",
    "glm_results = glm_model.fit()\n",
    "\n",
    "# Print the summary of the fixed effects model\n",
    "print(glm_results.summary())\n",
    "\n",
    "# Add the predicted fixed effects to the dataset\n",
    "model_fixed_object_data['fixed_effects'] = glm_results.fittedvalues\n",
    "\n",
    "# Construct the formula for the mixed effects model\n",
    "mixed_effects_formula = 'fixed_effects ~ 1'\n",
    "\n",
    "# Fit the mixed effects model using MixedLM\n",
    "mixed_model = smf.mixedlm(mixed_effects_formula, model_fixed_object_data, groups=model_fixed_object_data['site_id'], re_formula=\"~C(hour)+C(day)+C(week)\")\n",
    "mixed_results = mixed_model.fit()\n",
    "\n",
    "# Print the summary of the mixed effects model\n",
    "print(mixed_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bd7b1dc-caf5-4e66-b652-02f31379bc4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m exog_infl \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(exog_infl, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Fit the Zero-Inflated Poisson model\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m zip_model \u001b[38;5;241m=\u001b[39m \u001b[43mZeroInflatedPoisson\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_fixed_object_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcounts_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog_infl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog_infl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43minflation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     48\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m     51\u001b[0m zip_results \u001b[38;5;241m=\u001b[39m zip_model\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/count_model.py:601\u001b[0m, in \u001b[0;36mZeroInflatedPoisson.__init__\u001b[0;34m(self, endog, exog, exog_infl, offset, exposure, inflation, missing, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, exog_infl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, exposure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    600\u001b[0m              inflation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogit\u001b[39m\u001b[38;5;124m'\u001b[39m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 601\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mZeroInflatedPoisson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43minflation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minflation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mexog_infl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog_infl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mexposure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexposure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_main \u001b[38;5;241m=\u001b[39m Poisson(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[1;32m    607\u001b[0m                               exposure\u001b[38;5;241m=\u001b[39mexposure)\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m zipoisson\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/count_model.py:57\u001b[0m, in \u001b[0;36mGenericZeroInflated.__init__\u001b[0;34m(self, endog, exog, exog_infl, offset, inflation, exposure, missing, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, exog_infl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m              inflation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogit\u001b[39m\u001b[38;5;124m'\u001b[39m, exposure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGenericZeroInflated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mexposure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexposure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exog_infl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_inflate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:935\u001b[0m, in \u001b[0;36mCountModel.__init__\u001b[0;34m(self, endog, exog, offset, exposure, missing, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, exposure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    933\u001b[0m              check_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_kwargs(kwargs)\n\u001b[0;32m--> 935\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexposure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexposure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exposure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexposure \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexposure)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:185\u001b[0m, in \u001b[0;36mDiscreteModel.__init__\u001b[0;34m(self, endog, exog, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, check_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_rank \u001b[38;5;241m=\u001b[39m check_rank\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_on_perfect_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# keep for backwards compat\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_extra \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/base/data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/statsmodels/base/data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(PandasData, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "from statsmodels.discrete.count_model import ZeroInflatedPoisson\n",
    "\n",
    "# Define the counts column (e.g., 'car_counts') to model\n",
    "counts_column = 'person_counts'\n",
    "\n",
    "# Ensure all necessary data types are compatible and treat them as categorical\n",
    "model_fixed_object_data = hourly_averages.copy()\n",
    "model_fixed_object_data['hour'] = model_fixed_object_data['hour'].astype('category')\n",
    "model_fixed_object_data['day'] = model_fixed_object_data['day'].astype('category')\n",
    "model_fixed_object_data['week'] = model_fixed_object_data['week'].astype('category')\n",
    "model_fixed_object_data['year'] = model_fixed_object_data['year'].astype('category')\n",
    "model_fixed_object_data['site_id'] = model_fixed_object_data['site_id'].astype('category')\n",
    "\n",
    "# Prepare the fixed effects formula for the count model\n",
    "count_formula = f'{counts_column} ~ C(year) + C(hour) + C(day) + C(week)'\n",
    "\n",
    "# Prepare the fixed effects formula for the zero inflation model (logit model)\n",
    "# You can use different variables for the inflation model or the same\n",
    "infl_formula = '1'  # Simple model with only intercept, can be extended\n",
    "\n",
    "# Add the intercept to the count model (if not already included)\n",
    "model_fixed_object_data = sm.add_constant(model_fixed_object_data, prepend=False)\n",
    "\n",
    "# Fit the count model to get initial parameters\n",
    "count_model = smf.glm(count_formula, data=model_fixed_object_data, family=sm.families.Poisson())\n",
    "count_results = count_model.fit()\n",
    "\n",
    "# Extract the fitted values from the count model to use as an offset in the zero-inflation model\n",
    "model_fixed_object_data['offset'] = np.log(count_results.fittedvalues + 1e-5)\n",
    "\n",
    "# Define the exog and exog_infl for the Zero-Inflated Poisson model\n",
    "exog = model_fixed_object_data[['const', 'year', 'hour', 'day', 'week']]\n",
    "exog_infl = model_fixed_object_data[['const']]\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "exog = pd.get_dummies(exog, drop_first=True)\n",
    "exog_infl = pd.get_dummies(exog_infl, drop_first=True)\n",
    "\n",
    "# Fit the Zero-Inflated Poisson model\n",
    "zip_model = ZeroInflatedPoisson(\n",
    "    endog=model_fixed_object_data[counts_column],\n",
    "    exog=exog,\n",
    "    exog_infl=exog_infl,\n",
    "    inflation='logit'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "zip_results = zip_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(zip_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0be96-071f-4cee-9707-e07c499f39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.count_model import ZeroInflatedPoisson\n",
    "\n",
    "# Define the counts column (e.g., 'car_counts') to model\n",
    "counts_column = 'people_counts'\n",
    "\n",
    "# Ensure all necessary data types are compatible and treat them as categorical\n",
    "model_fixed_object_data = fixed_object_data.copy()\n",
    "model_fixed_object_data['hour'] = model_fixed_object_data['hour'].astype('category')\n",
    "model_fixed_object_data['day'] = model_fixed_object_data['day'].astype('category')\n",
    "model_fixed_object_data['week'] = model_fixed_object_data['week'].astype('category')\n",
    "model_fixed_object_data['year'] = model_fixed_object_data['year'].astype('category')\n",
    "model_fixed_object_data['site_id'] = model_fixed_object_data['site_id'].astype('category')\n",
    "\n",
    "# Fit the mixed effects model using MixedLM for random effects\n",
    "mixed_effects_formula = f'{counts_column} ~ year'\n",
    "mixed_model = smf.mixedlm(mixed_effects_formula, model_fixed_object_data, groups=model_fixed_object_data['site_id'], re_formula=\"~C(hour)+C(day)+C(week)\")\n",
    "mixed_results = mixed_model.fit()\n",
    "\n",
    "# Print the summary of the mixed effects model\n",
    "print(mixed_results.summary())\n",
    "\n",
    "# Use the fitted random effects from the mixed model\n",
    "model_fixed_object_data['mixed_effects'] = mixed_results.fittedvalues\n",
    "\n",
    "# Fit the Zero-Inflated Poisson model using the fixed effects\n",
    "zip_formula = f'{counts_column} ~ year'\n",
    "zip_model = ZeroInflatedPoisson.from_formula(\n",
    "    formula=zip_formula, \n",
    "    data=model_fixed_object_data,\n",
    "    exog_infl='1',\n",
    "    offset=model_fixed_object_data['mixed_effects'],\n",
    "    inflation='logit'\n",
    ")\n",
    "\n",
    "# Fit the zero-inflated model\n",
    "zip_results = zip_model.fit()\n",
    "\n",
    "# Print the summary of the zero-inflated model\n",
    "print(zip_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35d6ad-63de-48d2-9714-463f2f885586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
