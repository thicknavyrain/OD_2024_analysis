{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2663f99-474a-4644-b588-3aa71c13c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_names = {'AD': 'Asylum Down',\n",
    "             'ASH' : 'Ashaiman',\n",
    "             'EL': 'East Legon',\n",
    "             'JT' : 'James Town',\n",
    "             'LA': 'Labadi',\n",
    "             'N1W': 'N1 West Motorway',\n",
    "             'NM': 'Nima',\n",
    "             'TF': 'Taifa',\n",
    "             'TMW': 'Tema Motorway',\n",
    "             'UGH': 'University of Ghana'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de9f0823-6893-4cc5-8f86-f29f742077c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [05:11<00:00, 44.54s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to calculate the confidence intervals and coefficients\n",
    "def calculate_effects_and_ci(row):\n",
    "    coef = row['estimate']\n",
    "    lower = row['conf.low']\n",
    "    upper = row['conf.high']\n",
    "    return coef, lower, upper\n",
    "\n",
    "# Modified check_trend function to return detailed information\n",
    "def check_trend(estimates, lower_bounds, upper_bounds, num_bootstrap=10000):\n",
    "    # Remove NaNs from estimates\n",
    "    valid_indices = ~np.isnan(estimates)\n",
    "    estimates = estimates[valid_indices]\n",
    "    lower_bounds = lower_bounds[valid_indices]\n",
    "    upper_bounds = upper_bounds[valid_indices]\n",
    "    if len(estimates) < 2:\n",
    "        return {\n",
    "            'spearman_corr': None,\n",
    "            'spearman_ci': (None, None),\n",
    "            'is_significant': False\n",
    "        }\n",
    "\n",
    "    year_values = np.arange(len(estimates))\n",
    "\n",
    "    # Compute Spearman correlation on the central estimates\n",
    "    # corr, _ = spearmanr(year_values, estimates)\n",
    "\n",
    "    # Bootstrapping to estimate 95% CI of Spearman correlation\n",
    "    # Sampling from within the 95% confidence intervals of the estimates\n",
    "    bootstrap_corrs = []\n",
    "    for _ in range(num_bootstrap):\n",
    "        # For each estimate, sample a value from a uniform distribution between lower and upper bounds\n",
    "        if np.isnan(lower_bounds[1]):\n",
    "            print(lower_bounds)\n",
    "            print(upper_bounds)\n",
    "        sampled_estimates = np.random.uniform(lower_bounds, upper_bounds)\n",
    "        # Compute Spearman correlation\n",
    "        sample_corr, _ = spearmanr(year_values, sampled_estimates)\n",
    "        bootstrap_corrs.append(sample_corr)\n",
    "\n",
    "    # Compute 95% confidence interval\n",
    "    lower_ci = np.percentile(bootstrap_corrs, 2.5)\n",
    "    upper_ci = np.percentile(bootstrap_corrs, 97.5)\n",
    "    corr = np.percentile(bootstrap_corrs, 50)\n",
    "\n",
    "    # Determine significance\n",
    "    is_significant = (lower_ci > 0) or (upper_ci < 0)\n",
    "\n",
    "    return {\n",
    "        'spearman_corr': corr,\n",
    "        'spearman_ci': (lower_ci, upper_ci),\n",
    "        'is_significant': is_significant\n",
    "    }\n",
    "\n",
    "# Modified plotting function\n",
    "def plot_total_year_effects_all_sites_with_trends(sites, super_category, year_labels, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Modified colormap section\n",
    "    colormap = plt.get_cmap('tab10')  # Use 'get_cmap' to access the colormap\n",
    "    colors = [colormap(i % 10) for i in range(len(sites))]  # Correct way to get colors\n",
    "\n",
    "\n",
    "    all_estimates = []  # To track all central estimates for y-axis scaling\n",
    "    label_info_list = []  # To store label information for each site\n",
    "\n",
    "    for idx, site in enumerate(sites):\n",
    "        # Load the model data for the current site and category\n",
    "        filepath = f'./FULL_MODEL_RESULTS/{site}_{super_category}_conditional_model_coefficients.csv'\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found for {site} - {super_category}\")\n",
    "            continue\n",
    "\n",
    "        model_df = pd.read_csv(filepath)\n",
    "\n",
    "        estimates = [1]  # Adding the reference category (2019) with an effect of 1\n",
    "        lower_bounds = [1]  # The lower bound for the reference category\n",
    "        upper_bounds = [1]  # The upper bound for the reference category\n",
    "\n",
    "        # Iterate over the year labels to extract coefficients\n",
    "        for year in year_labels:\n",
    "            main_term = f'year{year}'\n",
    "            row = model_df[model_df['term'] == main_term]\n",
    "\n",
    "            if not row.empty:\n",
    "                coef, lower, upper = calculate_effects_and_ci(row.iloc[0])\n",
    "                estimates.append(coef)\n",
    "                lower_bounds.append(lower)\n",
    "                upper_bounds.append(upper)\n",
    "            else:\n",
    "                estimates.append(np.nan)\n",
    "                lower_bounds.append(np.nan)\n",
    "                upper_bounds.append(np.nan)\n",
    "\n",
    "        # Include '2019' in the labels for the reference category\n",
    "        full_year_labels = ['2019'] + year_labels\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        estimates = np.array(estimates)\n",
    "        lower_bounds = np.array(lower_bounds)\n",
    "        upper_bounds = np.array(upper_bounds)\n",
    "\n",
    "        # Keep track of all central estimates for setting y-axis limits later\n",
    "        all_estimates.extend(estimates[~np.isnan(estimates)])\n",
    "\n",
    "        # Compute trend_info\n",
    "        trend_info = check_trend(estimates, lower_bounds, upper_bounds)\n",
    "\n",
    "        # Identify valid data points\n",
    "        valid_indices = ~np.isnan(estimates)\n",
    "        x_values = np.arange(len(full_year_labels))[valid_indices]\n",
    "        estimates = estimates[valid_indices]\n",
    "        lower_bounds = lower_bounds[valid_indices]\n",
    "        upper_bounds = upper_bounds[valid_indices]\n",
    "        year_labels_valid = np.array(full_year_labels)[valid_indices]\n",
    "\n",
    "        # For significant trends, adjust plotting parameters\n",
    "        if trend_info['is_significant']:\n",
    "            zorder_line = 4\n",
    "            zorder_marker = 4\n",
    "            linewidth = 6\n",
    "            markersize = 12\n",
    "            alpha_line = 1\n",
    "            alpha_marker = 1\n",
    "\n",
    "            # Plot the white shadow effect behind the main lines and markers\n",
    "            plt.plot(\n",
    "                x_values,\n",
    "                estimates,\n",
    "                color='white',\n",
    "                linestyle='-',\n",
    "                linewidth=linewidth + 4,\n",
    "                alpha=1,\n",
    "                zorder=zorder_line - 1\n",
    "            )\n",
    "            plt.errorbar(\n",
    "                x_values,\n",
    "                estimates,\n",
    "                yerr=None,\n",
    "                fmt='o',\n",
    "                color='white',\n",
    "                markersize=markersize + 4,\n",
    "                alpha=1,\n",
    "                zorder=zorder_marker - 1\n",
    "            )\n",
    "        else:\n",
    "            # Default plotting parameters\n",
    "            zorder_line = 2\n",
    "            zorder_marker = 2\n",
    "            linewidth = 2\n",
    "            markersize = 8\n",
    "            alpha_line = 0.5\n",
    "            alpha_marker = 0.5\n",
    "\n",
    "        # Plot the whiskers (error bars)\n",
    "        plt.errorbar(\n",
    "            x_values,\n",
    "            estimates,\n",
    "            yerr=[estimates - lower_bounds, upper_bounds - estimates],\n",
    "            fmt='none',\n",
    "            ecolor=colors[idx],\n",
    "            alpha=0.125,\n",
    "            capsize=5,\n",
    "            elinewidth=1.5,\n",
    "            zorder=zorder_line - 1\n",
    "        )\n",
    "\n",
    "        # Plot lines connecting the points\n",
    "        plt.plot(\n",
    "            x_values,\n",
    "            estimates,\n",
    "            color=colors[idx],\n",
    "            linestyle='-',\n",
    "            linewidth=linewidth,\n",
    "            alpha=alpha_line,\n",
    "            zorder=zorder_line\n",
    "        )\n",
    "\n",
    "        # Plot the central points\n",
    "        plt.errorbar(\n",
    "            x_values,\n",
    "            estimates,\n",
    "            yerr=None,\n",
    "            fmt='o',\n",
    "            color=colors[idx],\n",
    "            capsize=5,\n",
    "            markersize=markersize,\n",
    "            alpha=alpha_marker,\n",
    "            elinewidth=1.5,\n",
    "            label=f'{site_names[site]}',\n",
    "            zorder=zorder_marker\n",
    "        )\n",
    "\n",
    "        # Collect label info\n",
    "        if len(estimates) > 0:\n",
    "            # Get the position of the last valid data point\n",
    "            last_x = x_values[-1]\n",
    "            label_x = len(full_year_labels) - 0.8  # Align labels at the same x-position\n",
    "            data_y = estimates[-1]\n",
    "\n",
    "            # Prepare label text\n",
    "            spearman_corr = trend_info['spearman_corr']\n",
    "            arrow = '▲' if (spearman_corr  > 0 and trend_info['is_significant']) else '▼' if (spearman_corr < 0 and trend_info['is_significant']) else ''\n",
    "            spearman_ci = trend_info['spearman_ci']\n",
    "            if spearman_corr is not None and spearman_ci[0] is not None and spearman_ci[1] is not None:\n",
    "                label_text = f\"{arrow} {spearman_corr:.2f} ({spearman_ci[0]:.2f}, {spearman_ci[1]:.2f})\"\n",
    "            else:\n",
    "                label_text = \"N/A\"\n",
    "\n",
    "            # Store label info\n",
    "            label_info_list.append({\n",
    "                'label_x': label_x,\n",
    "                'data_y': data_y,\n",
    "                'label_text': label_text,\n",
    "                'is_significant': trend_info['is_significant'],\n",
    "                'color': colors[idx],\n",
    "                'zorder': zorder_marker + 1,\n",
    "                'site': site,\n",
    "                'data_x': last_x\n",
    "            })\n",
    "\n",
    "    # Remove gridlines and adjust plot borders\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.grid(False)\n",
    "\n",
    "    # Add a thicker black line at y=1 to represent the reference level\n",
    "    plt.axhline(y=1, color='black', linewidth=2, linestyle='--')\n",
    "\n",
    "    # Set the y-axis limits\n",
    "    if all_estimates:\n",
    "        max_estimate = max(all_estimates)\n",
    "        min_estimate = min(all_estimates)\n",
    "        y_range = max_estimate - min_estimate\n",
    "        y_axis_min = min_estimate - y_range * 0.1\n",
    "        y_axis_max = max_estimate + y_range * 0.1\n",
    "        plt.ylim(y_axis_min, y_axis_max)\n",
    "    else:\n",
    "        y_axis_min, y_axis_max = plt.gca().get_ylim()\n",
    "        y_range = y_axis_max - y_axis_min\n",
    "\n",
    "    # Now adjust label positions to be evenly spaced from just above x-axis to just below top of y-axis\n",
    "    n_labels = len(label_info_list)\n",
    "    if n_labels > 1:\n",
    "        label_positions = np.linspace(y_axis_min + y_range * 0.05, y_axis_max - y_range * 0.05, n_labels)\n",
    "    else:\n",
    "        label_positions = [(y_axis_min + y_axis_max) / 2]\n",
    "\n",
    "    # Sort label_info_list by data_y (final y-values) ascending to maintain order from bottom to top\n",
    "    label_info_list.sort(key=lambda x: x['data_y'])\n",
    "\n",
    "    # Assign label y-positions according to the sorted order\n",
    "    for i, label_info in enumerate(label_info_list):\n",
    "        label_y = label_positions[i]\n",
    "        label_info['label_y'] = label_y\n",
    "\n",
    "    # Now plot labels and connectors\n",
    "    for label_info in label_info_list:\n",
    "        # Plot connector line from data point to label\n",
    "        plt.plot(\n",
    "            [label_info['data_x'], label_info['label_x']],\n",
    "            [label_info['data_y'], label_info['label_y']],\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=1,\n",
    "            zorder=label_info['zorder']\n",
    "        )\n",
    "\n",
    "        # Plot the label\n",
    "        bbox_props = dict(facecolor='white', alpha=1)\n",
    "        if label_info['is_significant']:\n",
    "            bbox_props['linewidth'] = 2  # Twice the line width for significant trends\n",
    "            fontsize = 14\n",
    "        else:\n",
    "            bbox_props['linewidth'] = 1\n",
    "            fontsize = 10\n",
    "\n",
    "        plt.text(\n",
    "            label_info['label_x'],\n",
    "            label_info['label_y'],\n",
    "            label_info['label_text'],\n",
    "            color=label_info['color'],\n",
    "            fontsize=fontsize,\n",
    "            va='center',\n",
    "            ha='left',\n",
    "            zorder=label_info['zorder'],\n",
    "            bbox=bbox_props\n",
    "        )\n",
    "\n",
    "    # Set x-ticks with labels\n",
    "    plt.xticks(ticks=range(len(full_year_labels)), labels=full_year_labels, rotation=45)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Multiplicative Effect on Counts')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    output_dir = './results/time_series_by_category/year/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'{output_dir}/{title.replace(\" \", \"_\")}_total_year_effects_{super_category}_median_trend.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Main execution\n",
    "sites = ['AD', 'ASH', 'EL', 'JT', 'LA', 'N1W', 'NM', 'TF', 'TMW', 'UGH']\n",
    "super_categories = ['people', 'small_vehicles', 'large_vehicles', 'market', 'two_wheelers', 'refuse', 'animal']\n",
    "\n",
    "for super_category in tqdm(super_categories):\n",
    "    # Plot total year effects for all sites, including trend annotations\n",
    "    year_labels = ['2020', '2021', '2022', '2023', '2024']  # Assuming '2019' as the reference\n",
    "    plot_total_year_effects_all_sites_with_trends(\n",
    "        sites,\n",
    "        super_category,\n",
    "        year_labels,\n",
    "        f'Total Effect of Year on {super_category.replace(\"_\",\" \").capitalize()} Counts'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5526a392-b617-43b9-9835-039f84b1b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to calculate the coefficients\n",
    "def calculate_effects_and_ci(row):\n",
    "    coef = row['estimate']\n",
    "    lower = row['conf.low']\n",
    "    upper = row['conf.high']\n",
    "    return coef, lower, upper\n",
    "\n",
    "# Function to combine main and interaction effects\n",
    "def combine_main_and_interaction_effects(main_row, interaction_row=None):\n",
    "    main_coef, _, _ = calculate_effects_and_ci(main_row)\n",
    "    \n",
    "    if interaction_row is not None and not interaction_row.empty:\n",
    "        inter_coef, _, _ = calculate_effects_and_ci(interaction_row.iloc[0])\n",
    "        combined_estimate = np.exp(np.log(main_coef) + np.log(inter_coef))\n",
    "    else:\n",
    "        combined_estimate = main_coef\n",
    "    \n",
    "    return combined_estimate\n",
    "\n",
    "# Function to get total day effects for a given model dataframe\n",
    "def get_total_day_effects(model_df, day_labels):\n",
    "    estimates = []\n",
    "    for day_idx, day in enumerate(day_labels, start=1):\n",
    "        if day == 'Monday':\n",
    "            # Monday is the reference category with an effect of 1\n",
    "            estimates.append(1)\n",
    "        else:\n",
    "            main_term = f'day{day_idx}'\n",
    "            main_row = model_df[model_df['term'] == main_term]\n",
    "            \n",
    "            interaction_estimates = []\n",
    "            # Combine main and interaction effects across all hours\n",
    "            for hour in range(1, 24):\n",
    "                interaction_term = f'hour{hour}:day{day_idx}'\n",
    "                interaction_row = model_df[model_df['term'] == interaction_term]\n",
    "                \n",
    "                if not main_row.empty and not interaction_row.empty:\n",
    "                    combined_estimate = combine_main_and_interaction_effects(\n",
    "                        main_row.iloc[0], interaction_row\n",
    "                    )\n",
    "                    interaction_estimates.append(combined_estimate)\n",
    "            if interaction_estimates:\n",
    "                # Average over all hours to get the day's effect\n",
    "                avg_estimate = np.mean(interaction_estimates)\n",
    "                estimates.append(avg_estimate)\n",
    "            else:\n",
    "                estimates.append(np.nan)\n",
    "    return estimates\n",
    "\n",
    "# Function to plot radar chart of day effects for all sites with scaling option\n",
    "def plot_radar_day_effects_all_sites(sites, super_category, day_labels, title, scale_by_median=False, ax=None):\n",
    "    site_day_effects = {}\n",
    "    site_day_effects_original = {}\n",
    "    for site in sites:\n",
    "        # Load model coefficients\n",
    "        filepath = f'./FULL_MODEL_RESULTS/{site}_{super_category}_conditional_model_coefficients.csv'\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"File not found for {site} - {super_category}\")\n",
    "            continue\n",
    "        model_df = pd.read_csv(filepath)\n",
    "        estimates = get_total_day_effects(model_df, day_labels)\n",
    "        site_day_effects[site] = estimates\n",
    "\n",
    "    # Apply scaling if requested\n",
    "    if scale_by_median:\n",
    "        site_day_effects_original = {}\n",
    "        for site in site_day_effects:\n",
    "            values = np.array(site_day_effects[site])\n",
    "            # Compute median excluding NaNs\n",
    "            median_value = np.nanmedian(values)\n",
    "            if median_value != 0:\n",
    "                # Scale values so that median becomes 1\n",
    "                values_scaled = values / median_value\n",
    "                # Divide by 2 so that median is at 0.5 on the plot\n",
    "                scaled_values = values_scaled / 2\n",
    "                site_day_effects[site] = scaled_values.tolist()\n",
    "                # Store values_scaled for labeling\n",
    "                site_day_effects_original[site] = values_scaled.tolist()\n",
    "            else:\n",
    "                # Avoid division by zero\n",
    "                site_day_effects[site] = values.tolist()\n",
    "                site_day_effects_original[site] = values.tolist()\n",
    "    else:\n",
    "        for site in site_day_effects:\n",
    "            site_day_effects_original[site] = site_day_effects[site]\n",
    "\n",
    "    # Number of variables we're plotting (7 days)\n",
    "    num_vars = len(day_labels)\n",
    "\n",
    "    # Split the circle into even parts and save the angles\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    # Complete the loop\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # If ax is None, create a new figure and axis\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,8), subplot_kw=dict(polar=True))\n",
    "\n",
    "    # Get the colormap\n",
    "    colormap = plt.get_cmap('tab10')\n",
    "    colors = [colormap(i % 10) for i in range(len(sites))]\n",
    "\n",
    "    # Dictionary to hold the labels for data points beyond the plot\n",
    "    labels_outside = {}\n",
    "\n",
    "    for idx_site, site in enumerate(site_day_effects.keys()):\n",
    "        values = np.array(site_day_effects[site])  # Values after scaling by median and dividing by 2\n",
    "        values_original = np.array(site_day_effects_original[site])  # Values after scaling by median\n",
    "        # Handle missing values (NaNs)\n",
    "        values = np.nan_to_num(values, nan=np.nan)\n",
    "        values_original = np.nan_to_num(values_original, nan=np.nan)\n",
    "        # Prepare lists for plotting\n",
    "        values_plot = values.tolist()\n",
    "        values_plot += values_plot[:1]\n",
    "        # Similarly for original values\n",
    "        values_original_plot = values_original.tolist()\n",
    "        values_original_plot += values_original_plot[:1]\n",
    "        # Plot the line for the site\n",
    "        ax.plot(angles, values_plot, label=site_names[site], color=colors[idx_site], linewidth=3)\n",
    "        # For values within the plot radius, plot the markers\n",
    "        for i, (angle, val_plot, val_original_plot) in enumerate(zip(angles, values_plot, values_original_plot)):\n",
    "            if not np.isnan(val_plot) and val_plot <= 1:\n",
    "                # Plot the marker\n",
    "                ax.scatter(angle, val_plot, color=colors[idx_site], s=75)\n",
    "            elif not np.isnan(val_plot) and val_plot > 1:\n",
    "                # Data point exceeds plot radius, collect for labeling\n",
    "                day = i % num_vars  # day index\n",
    "                if day not in labels_outside:\n",
    "                    labels_outside[day] = []\n",
    "                labels_outside[day].append({\n",
    "                    'site': site,\n",
    "                    'value': val_original_plot,  # value after scaling by median\n",
    "                    'color': colors[idx_site],\n",
    "                    'order': idx_site  # Keep track of site index for consistent ordering\n",
    "                })\n",
    "        # For the line, we need to handle data that goes beyond the plot\n",
    "        # Matplotlib will clip the line automatically\n",
    "\n",
    "    # Set the labels for each axis (day labels)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(day_labels)\n",
    "\n",
    "    # Adjust the radial limits\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    # Set radial ticks and labels\n",
    "    r_ticks = np.linspace(0, 1, 5)  # [0., 0.25, 0.5, 0.75, 1.]\n",
    "    r_tick_labels = [f\"{rtick*2:.1f}\" for rtick in r_ticks]  # Multiply by 2 to get back to values before dividing by 2\n",
    "    ax.set_yticks(r_ticks)\n",
    "    ax.set_yticklabels(r_tick_labels)\n",
    "\n",
    "    # Add a thicker black circular line at r=0.5 (which now represents the median)\n",
    "    theta_line = np.linspace(0, 2 * np.pi, 100)\n",
    "    r_line = np.ones_like(theta_line) * 0.5\n",
    "    ax.plot(theta_line, r_line, color='black', linewidth=3, linestyle='--')\n",
    "\n",
    "    # Now, handle the labels for data points beyond the plot\n",
    "    for day_idx in labels_outside:\n",
    "        day_angle = angles[day_idx]\n",
    "        entries = labels_outside[day_idx]\n",
    "        # Sort entries by value to determine placement (smaller values closer to plot)\n",
    "        entries_sorted = sorted(entries, key=lambda x: x['value'])\n",
    "        for idx_label, entry in enumerate(entries_sorted):\n",
    "            # Determine radial position for label\n",
    "            r_label = 1.3 + 0.2 * idx_label  # Adjust to prevent overlap\n",
    "            # Adjust angle slightly to prevent overlap with day labels\n",
    "            angle_offset = 0.0\n",
    "            if abs(day_angle - np.pi/2) < 0.1 or abs(day_angle - 3*np.pi/2) < 0.1:\n",
    "                angle_offset = 0.1 * (-1)**idx_label  # Adjust angle slightly\n",
    "            angle_label = day_angle + angle_offset\n",
    "            # Add label below the dot\n",
    "            ax.text(angle_label, r_label - 0.02, f\"●\\n{entry['value']:.2f}\", color=entry['color'],\n",
    "                    fontsize=14, ha='center', va='top')\n",
    "    # Adjust the plot to prevent labels from overlapping with day labels\n",
    "    ax.set_rlabel_position(0)  # Move radial labels away from day labels\n",
    "\n",
    "    # Add title to the subplot\n",
    "    ax.set_title(title, size=30, y=1.08)\n",
    "\n",
    "# Main execution\n",
    "sites = ['AD', 'ASH', 'EL', 'JT', 'LA', 'N1W', 'NM', 'TF', 'TMW', 'UGH'] \n",
    "super_categories = ['people', 'small_vehicles', 'large_vehicles', 'market', 'two_wheelers', 'refuse', 'animal'] \n",
    "day_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Create a 3x3 grid of subplots\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20, 20), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Define positions for the seven plots\n",
    "axes_positions = [ (0,0), (0,1), (0,2), (1,0), (1,1), (1,2), (2,1) ]\n",
    "\n",
    "for idx, (super_category, pos) in enumerate(zip(super_categories, axes_positions)):\n",
    "    ax = axs[pos[0]][pos[1]]\n",
    "    title = f'{super_category.replace(\"_\",\" \").capitalize()}'\n",
    "    plot_radar_day_effects_all_sites(\n",
    "        sites,\n",
    "        super_category,\n",
    "        day_labels,\n",
    "        title,\n",
    "        scale_by_median=True,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "# Turn off the axes for empty subplots\n",
    "axs[2][0].axis('off')\n",
    "axs[2][2].axis('off')\n",
    "\n",
    "# Get handles and labels from one of the axes (e.g., the first one)\n",
    "handles, labels = axs[0][0].get_legend_handles_labels()\n",
    "\n",
    "# Create a legend outside the subplots\n",
    "leg = fig.legend(handles, labels, loc='lower center', ncol=len(handles), bbox_to_anchor=(0.825, 0.25), ncols=2, fontsize=18)\n",
    "# set the linewidth of each legend object\n",
    "for legobj in leg.legend_handles:\n",
    "    legobj.set_linewidth(10)\n",
    "    \n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])  # Leave space at the bottom for the legend\n",
    "\n",
    "# Save the figure\n",
    "output_dir = f'./results/time_series_by_category/day/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "scaling_suffix = '_scaled_by_median'  # Since scale_by_median=True\n",
    "\n",
    "plt.savefig(f'{output_dir}/Total_Effect_of_Day_on_Counts_radar_plot{scaling_suffix}.png', bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7ead6-c24c-4ba1-bdba-0cae4e6a5bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
