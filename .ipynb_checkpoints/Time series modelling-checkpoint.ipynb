{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cc8a6-b346-40d5-adf0-62e50909193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095ac3ea-430b-4a4e-83e0-428ba0faec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.bayes_mixed_glm import PoissonBayesMixedGLM\n",
    "from tqdm import tqdm\n",
    "from patsy import dmatrices\n",
    "from patsy import dmatrix\n",
    "from statsmodels.discrete.count_model import ZeroInflatedPoisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0251927b-09b7-49ef-b966-05d4988eb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_data = pd.read_csv('./2024_Jul_ob_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6996374c-c0b0-4973-9d12-40f7c7b80f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of category names as they appear in the detections data. See paper for details of each category.\n",
    "categories = ['car', 'person', 'trotro', 'stall', 'truck', 'stove', 'motorcycle', 'vendor', 'lorry', 'umbrella', 'bus', 'trash', 'taxi', 'van', 'debris', 'loudspeaker', 'bowl', 'food', 'animal', 'bicycle']\n",
    "\n",
    "# Column names in the data frame for the number of counts of each category type in an image.\n",
    "count_cols = [cat+'_counts' for cat in categories]\n",
    "\n",
    "super_count_cols = ['people'+'_counts', 'small_vehicles'+'_counts', 'two_wheelers'+'_counts', 'large_vehicles'+'_counts', 'refuse'+'_counts', 'market'+'_counts', 'animal'+'_counts']\n",
    "\n",
    "all_count_cols = count_cols + super_count_cols\n",
    "\n",
    "vehicle_categories = ['car', 'trotro', 'truck', 'motorcycle', 'lorry', 'bus', 'taxi', 'van', 'bicycle']\n",
    "\n",
    "# Define super categories\n",
    "super_categories = {\n",
    "    'people': ['person', 'vendor'],\n",
    "    'small_vehicles': ['car', 'taxi', 'truck'],\n",
    "    'two_wheelers': ['bicycle', 'motorcycle'],\n",
    "    'large_vehicles': ['trotro', 'van', 'lorry', 'bus'],\n",
    "    'refuse': ['trash', 'debris'],\n",
    "    'market': ['umbrella', 'stall', 'bowl', 'food'],\n",
    "    'animal': ['animal']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc6bd7b-c000-4515-bd02-e192ea9eca95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directory_name_rectified</th>\n",
       "      <th>site_id_cam_angle</th>\n",
       "      <th>view</th>\n",
       "      <th>image_name</th>\n",
       "      <th>datetime_rectified</th>\n",
       "      <th>date_rectified</th>\n",
       "      <th>animal_counts</th>\n",
       "      <th>bicycle_counts</th>\n",
       "      <th>bowl_counts</th>\n",
       "      <th>bus_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>vendor_counts</th>\n",
       "      <th>directory_name_original</th>\n",
       "      <th>datetime_original</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>site_id</th>\n",
       "      <th>camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3070.JPG</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>2024-03-01 08:32:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3071.JPG</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>2024-03-01 08:37:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3072.JPG</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>2024-03-01 08:42:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3073.JPG</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>2024-03-01 08:47:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>AD_right</td>\n",
       "      <td>clear</td>\n",
       "      <td>MFDC3074.JPG</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>AD_01_03_2024_C22_S15</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>2024-03-01 08:52:02</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>AD</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  directory_name_rectified site_id_cam_angle   view    image_name  \\\n",
       "0    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3070.JPG   \n",
       "1    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3071.JPG   \n",
       "2    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3072.JPG   \n",
       "3    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3073.JPG   \n",
       "4    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3074.JPG   \n",
       "\n",
       "    datetime_rectified date_rectified  animal_counts  bicycle_counts  \\\n",
       "0  2024-03-01 08:32:02     2024-03-01              0               0   \n",
       "1  2024-03-01 08:37:02     2024-03-01              0               1   \n",
       "2  2024-03-01 08:42:02     2024-03-01              0               0   \n",
       "3  2024-03-01 08:47:02     2024-03-01              0               0   \n",
       "4  2024-03-01 08:52:02     2024-03-01              0               0   \n",
       "\n",
       "   bowl_counts  bus_counts  ...  vendor_counts  directory_name_original  \\\n",
       "0            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "1            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "2            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "3            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "4            0           0  ...              0    AD_01_03_2024_C22_S15   \n",
       "\n",
       "     datetime_original            datetime  hour  day  week  year  site_id  \\\n",
       "0  2024-03-01 08:32:02 2024-03-01 08:32:02     8    5     9  2024       AD   \n",
       "1  2024-03-01 08:37:02 2024-03-01 08:37:02     8    5     9  2024       AD   \n",
       "2  2024-03-01 08:42:02 2024-03-01 08:42:02     8    5     9  2024       AD   \n",
       "3  2024-03-01 08:47:02 2024-03-01 08:47:02     8    5     9  2024       AD   \n",
       "4  2024-03-01 08:52:02 2024-03-01 08:52:02     8    5     9  2024       AD   \n",
       "\n",
       "   camera  \n",
       "0   right  \n",
       "1   right  \n",
       "2   right  \n",
       "3   right  \n",
       "4   right  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure datetime is in datetime format\n",
    "object_data['datetime'] = pd.to_datetime(object_data['datetime_rectified'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Create additional time-related columns\n",
    "object_data['hour'] = object_data['datetime'].dt.hour\n",
    "object_data['day'] = object_data['datetime'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "object_data['week'] = object_data['datetime'].dt.isocalendar().week\n",
    "object_data['year'] = object_data['datetime'].dt.year\n",
    "\n",
    "# Split 'site_id_cam_angle' into 'site_id' and 'camera' columns\n",
    "object_data[['site_id', 'camera']] = object_data['site_id_cam_angle'].str.split('_', expand=True)\n",
    "\n",
    "# Fill missing values in 'camera' with 'single'\n",
    "object_data['camera'].fillna('single', inplace=True)\n",
    "\n",
    "# Filter data between specified dates\n",
    "start_date = pd.Timestamp('2019-04-01')\n",
    "end_date = pd.Timestamp('2024-04-01')\n",
    "fixed_object_data = object_data[(object_data['datetime'] >= start_date) & (object_data['datetime'] <= end_date)]\n",
    "fixed_object_data = fixed_object_data[fixed_object_data['view'] == 'clear']\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "fixed_object_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03aa3c9c-1c82-44cd-bd98-03d4de85848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum counts for each super category\n",
    "for super_cat, categories in super_categories.items():\n",
    "    # Create a column for each supercategory by summing its categories\n",
    "    fixed_object_data[super_cat + '_counts'] = fixed_object_data[[cat + '_counts' for cat in categories]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce8d8de0-2281-4169-9b79-c0bf05a83410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_object_data:\n",
      "  directory_name_rectified site_id_cam_angle   view    image_name  \\\n",
      "0    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3070.JPG   \n",
      "1    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3071.JPG   \n",
      "2    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3072.JPG   \n",
      "3    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3073.JPG   \n",
      "4    AD_01_03_2024_C22_S15          AD_right  clear  MFDC3074.JPG   \n",
      "\n",
      "    datetime_rectified date_rectified  animal_counts  bicycle_counts  \\\n",
      "0  2024-03-01 08:32:02     2024-03-01              0               0   \n",
      "1  2024-03-01 08:37:02     2024-03-01              0               1   \n",
      "2  2024-03-01 08:42:02     2024-03-01              0               0   \n",
      "3  2024-03-01 08:47:02     2024-03-01              0               0   \n",
      "4  2024-03-01 08:52:02     2024-03-01              0               0   \n",
      "\n",
      "   bowl_counts  bus_counts  ...  year  site_id  camera  people_counts  \\\n",
      "0            0           0  ...  2024       AD   right              7   \n",
      "1            0           0  ...  2024       AD   right              7   \n",
      "2            0           0  ...  2024       AD   right              7   \n",
      "3            0           0  ...  2024       AD   right              8   \n",
      "4            0           0  ...  2024       AD   right              5   \n",
      "\n",
      "   small_vehicles_counts  two_wheelers_counts  large_vehicles_counts  \\\n",
      "0                      1                    0                      0   \n",
      "1                      1                    1                      1   \n",
      "2                      1                    1                      1   \n",
      "3                      5                    1                      3   \n",
      "4                      3                    0                      0   \n",
      "\n",
      "   refuse_counts  market_counts       datetime_hour  \n",
      "0              1              0 2024-03-01 09:00:00  \n",
      "1              1              0 2024-03-01 09:00:00  \n",
      "2              2              0 2024-03-01 09:00:00  \n",
      "3              1              0 2024-03-01 09:00:00  \n",
      "4              0              0 2024-03-01 09:00:00  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "hourly_counts:\n",
      "  site_id camera       datetime_hour directory_name_rectified  car_counts  \\\n",
      "0      AD   left 2019-04-12 11:00:00        AD_12_04_2019_C17         334   \n",
      "1      AD   left 2019-04-12 12:00:00        AD_12_04_2019_C17         458   \n",
      "2      AD   left 2019-04-12 13:00:00        AD_12_04_2019_C17         557   \n",
      "3      AD   left 2019-04-12 14:00:00        AD_12_04_2019_C17         502   \n",
      "4      AD   left 2019-04-12 15:00:00        AD_12_04_2019_C17         504   \n",
      "\n",
      "   person_counts  trotro_counts  stall_counts  truck_counts  stove_counts  \\\n",
      "0            148             36             0            20             0   \n",
      "1            218             65             0            36             0   \n",
      "2            179             54             0            35             0   \n",
      "3            182             86             0            12             0   \n",
      "4            230             54             0            17             0   \n",
      "\n",
      "   ...  food_counts  animal_counts  bicycle_counts  people_counts  \\\n",
      "0  ...            0              0               0            149   \n",
      "1  ...            0              0               2            219   \n",
      "2  ...            0              0               0            180   \n",
      "3  ...            0              0               1            182   \n",
      "4  ...            0              0               1            231   \n",
      "\n",
      "   small_vehicles_counts  two_wheelers_counts  large_vehicles_counts  \\\n",
      "0                    403                   11                     41   \n",
      "1                    549                   11                     76   \n",
      "2                    674                   12                     69   \n",
      "3                    578                   18                     92   \n",
      "4                    581                   27                     62   \n",
      "\n",
      "   refuse_counts  market_counts  animal_counts  \n",
      "0              0             28              0  \n",
      "1              1             35              0  \n",
      "2              3             33              0  \n",
      "3              0             22              0  \n",
      "4              0             32              0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Aggregation dictionary:\n",
      "{'car_counts': 'mean', 'person_counts': 'mean', 'trotro_counts': 'mean', 'stall_counts': 'mean', 'truck_counts': 'mean', 'stove_counts': 'mean', 'motorcycle_counts': 'mean', 'vendor_counts': 'mean', 'lorry_counts': 'mean', 'umbrella_counts': 'mean', 'bus_counts': 'mean', 'trash_counts': 'mean', 'taxi_counts': 'mean', 'van_counts': 'mean', 'debris_counts': 'mean', 'loudspeaker_counts': 'mean', 'bowl_counts': 'mean', 'food_counts': 'mean', 'animal_counts': 'mean', 'bicycle_counts': 'mean', 'people_counts': 'mean', 'small_vehicles_counts': 'mean', 'two_wheelers_counts': 'mean', 'large_vehicles_counts': 'mean', 'refuse_counts': 'mean', 'market_counts': 'mean', 'directory_name_rectified': <function aggregate_directories at 0x7fe2119a98a0>, 'camera': <function aggregate_cameras at 0x7fe2119a99e0>}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4809/2154303735.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Perform the aggregation step by step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhourly_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'site_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'datetime_hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Aggregate numeric columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mhourly_averages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_count_cols\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Aggregate directory_name_rectified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mhourly_averages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'directory_name_rectified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'directory_name_rectified'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggregate_directories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0;31m# GH #52849\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_index\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \"\"\"\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_or_apply_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         with com.temp_setattr(\n\u001b[1;32m   1386\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         ):\n\u001b[0;32m-> 1388\u001b[0;31m             result_index, result_data = self.compute_dict_like(\n\u001b[0m\u001b[1;32m   1389\u001b[0m                 \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m             )\n\u001b[1;32m   1391\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_results_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mkeys\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkey_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# key used for column selection and output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             results = [\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    479\u001b[0m     def compute_dict_like(\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0mop_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mselected_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mselection\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;31m# Not all agg functions support numba, only propagate numba kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;31m# if user asks for numba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"engine_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;31m# Catch instances of lists / tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2371\u001b[0m                 \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2372\u001b[0m                 \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             )\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m             result = self._cython_agg_general(\n\u001b[0m\u001b[1;32m   2376\u001b[0m                 \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m                 \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                 \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_py_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m         \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1928\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_aggregated_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, mgr)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_agged_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mManager\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'datetime_hour' is created properly\n",
    "fixed_object_data['datetime_hour'] = fixed_object_data['datetime'].dt.round('H')\n",
    "assert 'datetime_hour' in fixed_object_data.columns, \"'datetime_hour' column is missing\"\n",
    "\n",
    "# Print the first few rows of fixed_object_data to verify 'datetime_hour'\n",
    "print(\"fixed_object_data:\")\n",
    "print(fixed_object_data.head())\n",
    "\n",
    "# Sum the counts within each hour for each camera at each site and include directory_name_rectified and camera info\n",
    "hourly_counts = fixed_object_data.groupby(['site_id', 'camera', 'datetime_hour', 'directory_name_rectified'])[all_count_cols].sum().reset_index()\n",
    "assert 'datetime_hour' in hourly_counts.columns, \"'datetime_hour' column is missing after groupby\"\n",
    "\n",
    "# Print the first few rows of hourly_counts to verify the groupby operation\n",
    "print(\"\\nhourly_counts:\")\n",
    "print(hourly_counts.head())\n",
    "\n",
    "# Define the aggregation functions for each column\n",
    "def aggregate_directories(x):\n",
    "    print(\"Aggregating directories:\", x)\n",
    "    return '|'.join(sorted(set(x)))\n",
    "\n",
    "def aggregate_cameras(x):\n",
    "    print(\"Aggregating cameras:\", x)\n",
    "    return ','.join(sorted(set(x)))\n",
    "\n",
    "# Group by the rounded 'datetime', 'site_id', then calculate the mean for each object category\n",
    "agg_dict = {col: 'mean' for col in all_count_cols}\n",
    "agg_dict['directory_name_rectified'] = aggregate_directories\n",
    "agg_dict['camera'] = aggregate_cameras\n",
    "\n",
    "print(\"Aggregation dictionary:\")\n",
    "print(agg_dict)\n",
    "\n",
    "# Perform the aggregation step by step\n",
    "grouped = hourly_counts.groupby(['site_id', 'datetime_hour'])\n",
    "\n",
    "# Aggregate numeric columns\n",
    "hourly_averages = grouped.agg({col: 'mean' for col in all_count_cols}).reset_index()\n",
    "\n",
    "# Aggregate directory_name_rectified\n",
    "hourly_averages['directory_name_rectified'] = grouped['directory_name_rectified'].apply(aggregate_directories).values\n",
    "\n",
    "# Aggregate camera\n",
    "hourly_averages['camera'] = grouped['camera'].apply(aggregate_cameras).values\n",
    "\n",
    "assert 'datetime_hour' in hourly_averages.columns, \"'datetime_hour' column is missing after aggregation\"\n",
    "\n",
    "# Print the first few rows of hourly_averages to verify the aggregation\n",
    "print(\"\\nhourly_averages:\")\n",
    "print(hourly_averages.head())\n",
    "\n",
    "# Add the date column from the rounded 'datetime_hour'\n",
    "hourly_averages['date'] = hourly_averages['datetime_hour'].dt.date\n",
    "\n",
    "# Create additional time-related columns\n",
    "hourly_averages['hour'] = hourly_averages['datetime_hour'].dt.hour\n",
    "hourly_averages['day'] = hourly_averages['datetime_hour'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "hourly_averages['week'] = hourly_averages['datetime_hour'].dt.isocalendar().week\n",
    "hourly_averages['year'] = hourly_averages['datetime_hour'].dt.year\n",
    "\n",
    "# Add the left and right camera indicator columns\n",
    "hourly_averages['left_cam'] = hourly_averages['camera'].apply(lambda x: 1 if 'left' in x else 0)\n",
    "hourly_averages['right_cam'] = hourly_averages['camera'].apply(lambda x: 1 if 'right' in x else 0)\n",
    "\n",
    "# Reorder the columns to match the requested format\n",
    "final_columns = ['datetime_hour', 'date', 'site_id', 'hour', 'day', 'week', 'year', 'directory_name_rectified', 'left_cam', 'right_cam'] + all_count_cols\n",
    "hourly_averages = hourly_averages[final_columns]\n",
    "\n",
    "# Rename 'datetime_hour' to 'datetime' to match the final requested column name\n",
    "hourly_averages.rename(columns={'datetime_hour': 'datetime', 'directory_name_rectified': 'directory_pair'}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "print(\"\\nfinal hourly_averages:\")\n",
    "print(hourly_averages.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c13aec-e259-46dd-b08b-bd60886ed36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Round the 'datetime' to the nearest hour\n",
    "fixed_object_data['datetime_hour'] = fixed_object_data['datetime'].dt.round('H')\n",
    "\n",
    "# Step 8: Sum the counts within each hour for each camera at each site\n",
    "hourly_counts = fixed_object_data.groupby(['site_id', 'camera', 'datetime_hour'])[all_count_cols].sum().reset_index()\n",
    "\n",
    "# Step 9: Group by the rounded 'datetime', 'date', and 'site_id', then calculate the mean for each object category\n",
    "hourly_averages = hourly_counts.groupby(['site_id', 'datetime_hour'])[all_count_cols].mean().reset_index()\n",
    "\n",
    "# Step 10: Add the date column from the rounded 'datetime_hour'\n",
    "hourly_averages['date'] = hourly_averages['datetime_hour'].dt.date\n",
    "\n",
    "# Create additional time-related columns\n",
    "hourly_averages['hour'] = hourly_averages['datetime_hour'].dt.hour\n",
    "hourly_averages['day'] = hourly_averages['datetime_hour'].dt.dayofweek + 1  # +1 to match R's 1-indexing\n",
    "hourly_averages['week'] = hourly_averages['datetime_hour'].dt.isocalendar().week\n",
    "hourly_averages['year'] = hourly_averages['datetime_hour'].dt.year\n",
    "\n",
    "\n",
    "# Step 11: Reorder the columns to match the requested format\n",
    "final_columns = ['datetime_hour', 'date', 'site_id', 'hour', 'day', 'week', 'year'] + all_count_cols\n",
    "hourly_averages = hourly_averages[final_columns]\n",
    "\n",
    "# Step 12: Rename 'datetime_hour' to 'datetime' to match the final requested column name\n",
    "hourly_averages.rename(columns={'datetime_hour': 'datetime'}, inplace=True)\n",
    "\n",
    "# Display the first few rows of the new dataframe to verify\n",
    "hourly_averages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6ed03-1af3-4168-877e-95172e35f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a function to determine the directory pair or single directory for each row\n",
    "def get_directory_name(row):\n",
    "    # Filter rows for the same site and datetime\n",
    "    matching_rows = fixed_object_data[(fixed_object_data['site_id'] == row['site_id']) & \n",
    "                                      (fixed_object_data['datetime_hour'] == row['datetime'])]\n",
    "    # Get unique directories and cameras\n",
    "    unique_dirs = matching_rows['directory_name_rectified'].unique()\n",
    "    unique_cameras = matching_rows['camera'].unique()\n",
    "    \n",
    "    if len(unique_dirs) == 1:\n",
    "        return unique_dirs[0]  # Single camera or only one camera available\n",
    "    else:\n",
    "        return '|'.join(sorted(unique_dirs))  # Join directories with '|' to indicate pairs\n",
    "\n",
    "# Initialize the tqdm progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply the function to create the new column with progress monitoring\n",
    "hourly_averages['directory_pair'] = hourly_averages.progress_apply(get_directory_name, axis=1)\n",
    "\n",
    "# Create indicator variables for left and right cameras\n",
    "hourly_averages['left_cam'] = hourly_averages.progress_apply(\n",
    "    lambda row: 1 if 'left' in fixed_object_data[(fixed_object_data['site_id'] == row['site_id']) & \n",
    "                                                 (fixed_object_data['datetime_hour'] == row['datetime'])]['camera'].unique() else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "hourly_averages['right_cam'] = hourly_averages.progress_apply(\n",
    "    lambda row: 1 if 'right' in fixed_object_data[(fixed_object_data['site_id'] == row['site_id']) & \n",
    "                                                  (fixed_object_data['datetime_hour'] == row['datetime'])]['camera'].unique() else 0,\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561fa96-75a2-4469-a91f-226f12c7a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the new dataframe to verify\n",
    "hourly_averages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e4adc2-5b77-44c0-8bdd-82df77b2a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Decide whether to include \"week\" as a variable or not\n",
    "week_bool = True\n",
    "\n",
    "# OPTIONAL Step 1: Filter the data to include only those rows with counts > 0\n",
    "filtered_data = hourly_averages.copy()\n",
    "# filtered_data = hourly_averages[hourly_averages['people_counts'] > 0].copy()\n",
    "\n",
    "# Step 2: Create the endogenous variable (response variable)\n",
    "endog = filtered_data['people_counts'].astype(int)\n",
    "\n",
    "# Step 3: Convert relevant columns to categorical\n",
    "filtered_data['hour'] = filtered_data['hour'].astype('category')\n",
    "filtered_data['day'] = filtered_data['day'].astype('category')\n",
    "if week_bool == True:\n",
    "    filtered_data['week'] = filtered_data['week'].astype('category')\n",
    "filtered_data['site_id'] = filtered_data['site_id'].astype('category')\n",
    "filtered_data['year'] = filtered_data['year'].astype('category')\n",
    "\n",
    "# Step 4: One-hot encode 'hour', 'day', 'week', 'site_id', and 'year' for fixed effects\n",
    "if week_bool == True:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id', 'year']], drop_first=True)\n",
    "else:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'site_id', 'year']], drop_first=True)\n",
    "\n",
    "# Step 5: Add intercept\n",
    "exog_fixed = sm.add_constant(exog_fixed)\n",
    "\n",
    "# Step 6: Convert exog_fixed to float\n",
    "exog_fixed = exog_fixed.astype(float)\n",
    "\n",
    "# Step 7: Fit the GLM with a Negative Binomial family\n",
    "glm_model = sm.GLM(endog, exog_fixed, family=sm.families.NegativeBinomial())\n",
    "# glm_model = sm.GLM(endog, exog_fixed, family=sm.families.Poisson())\n",
    "glm_result = glm_model.fit()\n",
    "\n",
    "# Step 8: Display the results of the fixed effects\n",
    "print(glm_result.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08657dbf-96bc-4a34-ad95-e0fdef5d4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate the confidence intervals and exponentiate the coefficients\n",
    "def calculate_effects_and_ci(glm_result, var):\n",
    "    coef = glm_result.params[var]\n",
    "    conf = glm_result.conf_int().loc[var]\n",
    "    lower, upper = conf\n",
    "    return np.exp(coef), np.exp(lower), np.exp(upper)\n",
    "\n",
    "# Function to plot effects for a given variable\n",
    "def plot_effects(glm_result, var, x_labels, title, ref_class_label):\n",
    "    effects = [calculate_effects_and_ci(glm_result, v) for v in var]\n",
    "    estimates, lower_bounds, upper_bounds = zip(*effects)\n",
    "    \n",
    "    # Add the reference class at the start\n",
    "    estimates = [1] + list(estimates)\n",
    "    lower_bounds = [1] + list(lower_bounds)\n",
    "    upper_bounds = [1] + list(upper_bounds)\n",
    "    x_labels = [ref_class_label] + x_labels\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.errorbar(range(len(x_labels)), estimates, yerr=[np.array(estimates) - np.array(lower_bounds), np.array(upper_bounds) - np.array(estimates)], fmt='o', ecolor='gray', capsize=5)\n",
    "    plt.xticks(ticks=range(len(x_labels)), labels=x_labels, rotation=45)\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Multiplicative Effect on Counts')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Highlight the reference class differently\n",
    "    plt.scatter(0, 1, color='red', zorder=5, label='Reference Class')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Variables to plot\n",
    "hour_vars = [col for col in exog_fixed.columns if 'hour' in col and col != 'const']\n",
    "day_vars = [col for col in exog_fixed.columns if 'day' in col and col != 'const']\n",
    "site_vars = [col for col in exog_fixed.columns if 'site_id' in col and col != 'const']\n",
    "year_vars = [col for col in exog_fixed.columns if 'year' in col and col != 'const']\n",
    "week_vars = [col for col in exog_fixed.columns if 'week' in col and col != 'const'] if week_bool else []\n",
    "\n",
    "# X-axis labels\n",
    "hour_labels = [f'Hour {i}' for i in range(1, 24)]\n",
    "day_labels = ['Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']  # Assuming 'Mon' is the reference category\n",
    "site_labels = [label.split('_')[2] for label in site_vars]\n",
    "year_labels = [label.split('_')[1] for label in year_vars]\n",
    "week_labels = [label.split('_')[1] for label in week_vars]\n",
    "\n",
    "# Ensure the number of labels matches the number of data points\n",
    "assert len(hour_labels) == len(hour_vars)\n",
    "assert len(day_labels) == len(day_vars)\n",
    "assert len(site_labels) == len(site_vars)\n",
    "assert len(year_labels) == len(year_vars)\n",
    "if week_bool:\n",
    "    assert len(week_labels) == len(week_vars)\n",
    "\n",
    "# Plot effects\n",
    "plot_effects(glm_result, hour_vars, hour_labels, 'Effect of Hour of Day on People Counts', 'Hour 0')\n",
    "plot_effects(glm_result, day_vars, day_labels, 'Effect of Day of Week on People Counts', 'Mon')\n",
    "plot_effects(glm_result, site_vars, site_labels, 'Effect of Site ID on People Counts', 'AD')\n",
    "plot_effects(glm_result, year_vars, year_labels, 'Effect of Year on People Counts', '2019')\n",
    "\n",
    "if week_bool:\n",
    "    plot_effects(glm_result, week_vars, week_labels, 'Effect of Week on People Counts', 'Week 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff25623-0d21-4385-bce6-2ea2a9cedb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Decide whether to include \"week\" as a variable or not\n",
    "week_bool = False\n",
    "\n",
    "# OPTIONAL Step 1: Filter the data to include only those rows with counts > 0\n",
    "filtered_data = hourly_averages.copy()\n",
    "# filtered_data = hourly_averages[hourly_averages['people_counts'] > 0].copy()\n",
    "\n",
    "# Step 2: Create the endogenous variable (response variable)\n",
    "endog = filtered_data['people_counts'].astype(int)\n",
    "\n",
    "# Step 3: Convert relevant columns to categorical\n",
    "filtered_data['hour'] = filtered_data['hour'].astype('category')\n",
    "filtered_data['day'] = filtered_data['day'].astype('category')\n",
    "if week_bool == True:\n",
    "    filtered_data['week'] = filtered_data['week'].astype('category')\n",
    "filtered_data['site_id'] = filtered_data['site_id'].astype('category')\n",
    "filtered_data['year'] = filtered_data['year'].astype('category')\n",
    "\n",
    "# Step 4: One-hot encode 'hour', 'day', 'week', 'site_id', and 'year' for fixed effects\n",
    "if week_bool == True:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id', 'year']], drop_first=True)\n",
    "else:\n",
    "    exog_fixed = pd.get_dummies(filtered_data[['hour', 'day', 'site_id', 'year']], drop_first=True)\n",
    "\n",
    "# Add back the reference classes manually\n",
    "exog_fixed['hour_0'] = (filtered_data['hour'] == '0').astype(float)\n",
    "exog_fixed['day_1'] = (filtered_data['day'] == '1').astype(float)\n",
    "exog_fixed['site_id_AD'] = (filtered_data['site_id'] == 'AD').astype(float)\n",
    "\n",
    "# Step 5: Add interaction terms efficiently\n",
    "interaction_terms_list = []\n",
    "for col1 in ['hour_0'] + [f'hour_{i}' for i in range(1, 24)]:\n",
    "    for col2 in ['day_1'] + [f'day_{i}' for i in range(2, 8)]:\n",
    "        interaction_terms_list.append(exog_fixed[col1] * exog_fixed[col2])\n",
    "        interaction_terms_list[-1].name = f'{col1}:{col2}'\n",
    "    for col2 in ['site_id_AD'] + [f'site_id_{id}' for id in ['ASH', 'EL', 'JT', 'LA', 'N1W', 'NM', 'TF', 'TMW', 'UGH']]:\n",
    "        interaction_terms_list.append(exog_fixed[col1] * exog_fixed[col2])\n",
    "        interaction_terms_list[-1].name = f'{col1}:{col2}'\n",
    "for col1 in ['day_1'] + [f'day_{i}' for i in range(2, 8)]:\n",
    "    for col2 in ['site_id_AD'] + [f'site_id_{id}' for id in ['ASH', 'EL', 'JT', 'LA', 'N1W', 'NM', 'TF', 'TMW', 'UGH']]:\n",
    "        interaction_terms_list.append(exog_fixed[col1] * exog_fixed[col2])\n",
    "        interaction_terms_list[-1].name = f'{col1}:{col2}'\n",
    "\n",
    "interaction_terms = pd.concat(interaction_terms_list, axis=1)\n",
    "\n",
    "# Combine the original exog_fixed with interaction terms\n",
    "exog_fixed = pd.concat([exog_fixed, interaction_terms], axis=1)\n",
    "\n",
    "# Step 6: Add intercept\n",
    "exog_fixed = sm.add_constant(exog_fixed)\n",
    "\n",
    "# Step 7: Convert exog_fixed to float\n",
    "exog_fixed = exog_fixed.astype(float)\n",
    "\n",
    "# Step 8: Fit the GLM with a Negative Binomial family\n",
    "glm_model = sm.GLM(endog, exog_fixed, family=sm.families.NegativeBinomial())\n",
    "# glm_model = sm.GLM(endog, exog_fixed, family=sm.families.Poisson())\n",
    "glm_result = glm_model.fit()\n",
    "\n",
    "# Step 9: Display the results of the fixed effects\n",
    "print(glm_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dfa8f-b0a6-45ed-874e-e122cfc7cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Prepare data for random effects model\n",
    "# Note: MixedLM in statsmodels is primarily for linear mixed models and does not support Negative Binomial directly\n",
    "\n",
    "# Fit the mixed effects model with random effects\n",
    "if week_bool == True:\n",
    "    random_effects = pd.get_dummies(filtered_data[['hour', 'day', 'week', 'site_id']], drop_first=True)\n",
    "else:\n",
    "    random_effects = pd.get_dummies(filtered_data[['hour', 'day', 'site_id']], drop_first=True)\n",
    "\n",
    "random_effects = sm.add_constant(random_effects).astype(float)\n",
    "\n",
    "mixed_model = sm.MixedLM(endog, exog_fixed, groups=filtered_data['site_id'])\n",
    "mixed_result = mixed_model.fit()\n",
    "\n",
    "# Step 10: Display the results of the mixed effects model\n",
    "print(mixed_result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7708c9-de40-4c21-bbc1-ed54e8753bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
